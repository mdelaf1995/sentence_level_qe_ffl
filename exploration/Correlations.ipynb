{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import en_core_web_md\n",
    "import de_core_news_md\n",
    "nlp_en = en_core_web_md.load()\n",
    "nlp_ge = de_core_news_md.load()\n",
    "\n",
    "def spacy_analysis(sentence,nlp):\n",
    "    doc = nlp(sentence)\n",
    "    for token in doc:\n",
    "        print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "              token.shape_, token.is_alpha, token.is_stop,token.vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_pickle(\"../data/dataset_train_val_final.pickle\")\n",
    "with open(\"../data/vocab_en.pkl\", 'rb') as f:\n",
    "    vocab_2_embedding_idx_en = pickle.load(f)\n",
    "with open(\"../data/vocab_ge.pkl\", 'rb') as f:\n",
    "    vocab_2_embedding_idx_ge = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "\n",
    "def load_vec(emb_path, nmax=50000):\n",
    "    vectors = []\n",
    "    word2id = {}\n",
    "    with io.open(emb_path, 'r', encoding='utf-8', newline='\\n', errors='ignore') as f:\n",
    "        next(f)\n",
    "        for i, line in enumerate(f):\n",
    "            word, vect = line.rstrip().split(' ', 1)\n",
    "            vect = np.fromstring(vect, sep=' ')\n",
    "            assert word not in word2id, 'word found twice'\n",
    "            vectors.append(vect)\n",
    "            word2id[word] = len(word2id)\n",
    "            if len(word2id) == nmax:\n",
    "                break\n",
    "    id2word = {v: k for k, v in word2id.items()}\n",
    "    embeddings = np.vstack(vectors)\n",
    "    return embeddings, id2word, word2id\n",
    "\n",
    "path = os.path.join(os.path.dirname(os.getcwd()), 'data','muse')\n",
    "\n",
    "src_path = path+\"/wiki.multi.en.vec\"\n",
    "tgt_path = path+\"/wiki.multi.de.vec\"\n",
    "nmax = 300000  # maximum number of word embeddings to load\n",
    "\n",
    "src_embeddings, src_id2word, src_word2id = load_vec(src_path, nmax)\n",
    "tgt_embeddings, tgt_id2word, tgt_word2id = load_vec(tgt_path, nmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation(src_emb,tgt_emb):\n",
    "    corr = (src_emb / np.linalg.norm(src_emb)).dot(tgt_emb / np.linalg.norm(tgt_emb))\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emb(word,language):\n",
    "    if language==\"en\":\n",
    "        return src_embeddings[vocab_2_embedding_idx_en[word]]\n",
    "    else:\n",
    "        return tgt_embeddings[vocab_2_embedding_idx_ge[word]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corr_matrix(words_en_list,words_ge_list):\n",
    "    n = len(words_en_list)\n",
    "    m = len(words_ge_list)\n",
    "    corr_matrix = np.zeros((n,m))\n",
    "    for i,word_en in enumerate(words_en_list):\n",
    "        for j,word_ge in enumerate(words_ge_list):\n",
    "            corr_matrix[i,j] = get_correlation(get_emb(word_en,\"en\"),get_emb(word_ge,\"ge\"))\n",
    "            \n",
    "    return corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_matches(corr_matrix):\n",
    "    if len(corr_matrix)==0:\n",
    "        return {}\n",
    "    best_match_row = np.argmax(corr_matrix,axis=0)\n",
    "    best_match_col = np.argmax(corr_matrix,axis=1)\n",
    "    couples = {}\n",
    "    tmp_corr_matrix = corr_matrix.copy()\n",
    "    n = corr_matrix.shape[0] \n",
    "    m = corr_matrix.shape[1]\n",
    "    dim = min(n,m)\n",
    "    while len(couples.keys())<dim:\n",
    "        for i in range(n):\n",
    "            if (i == best_match_row[best_match_col[i]]) and (i not in couples.keys()):\n",
    "                couples[i] = best_match_col[i]\n",
    "                tmp_corr_matrix[i,:] = np.zeros(m)\n",
    "                tmp_corr_matrix[:,best_match_col[i]] = np.zeros(n)\n",
    "                best_match_row = np.argmax(tmp_corr_matrix,axis=0)\n",
    "                best_match_col = np.argmax(tmp_corr_matrix,axis=1)\n",
    "    return couples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = np.array([[1,2,3],\n",
    "                [4,5,6],\n",
    "                [7,8,9],\n",
    "                [10,11,12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_couples(words_en,words_ge):\n",
    "    if len(words_en)==0 or len(words_ge)==0:\n",
    "        return np.nan,np.nan,np.nan\n",
    "    \n",
    "    words_en_list = words_en.split()\n",
    "    words_ge_list = words_ge.split()\n",
    "    corr_mat = get_corr_matrix(words_en_list,words_ge_list)\n",
    "    word_couples_idx = get_word_matches(corr_mat)\n",
    "    score = 0\n",
    "    \n",
    "    for i in word_couples_idx.keys():\n",
    "        score+=corr_mat[i,word_couples_idx[i]]\n",
    "    score/=len(word_couples_idx)\n",
    "    \n",
    "    if len(words_en_list)>len(words_ge_list):\n",
    "        kept_words_idx = np.array(list(word_couples_idx.keys()))\n",
    "        left_words_idx = np.setdiff1d(np.arange(len(words_en_list)),kept_words_idx)\n",
    "        left_words = [words_en_list[i] for i in left_words_idx]\n",
    "        \n",
    "    elif len(words_en_list)<len(words_ge_list):\n",
    "        kept_words_idx = np.array(list(word_couples_idx.values()))\n",
    "        left_words_idx = np.setdiff1d(np.arange(len(words_en_list)),kept_words_idx)\n",
    "        left_words = [words_ge_list[i] for i in left_words_idx]\n",
    "        \n",
    "    else:\n",
    "        left_words = []\n",
    "        \n",
    "    word_couples = {}\n",
    "    for key,val in word_couples_idx.items():\n",
    "        word_couples[words_en_list[key]] = words_ge_list[val]\n",
    "        \n",
    "    return word_couples,score,left_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"correlation\"] = dataset.apply(lambda row:get_word_couples(row[\"sentences_en_final\"],row[\"sentences_ge_final\"])[1],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"correlation\"] = dataset[\"correlation\"].fillna(dataset[\"correlation\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correlation</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>correlation</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.089792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores</th>\n",
       "      <td>0.089792</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             correlation    scores\n",
       "correlation     1.000000  0.089792\n",
       "scores          0.089792  1.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[[\"correlation\",\"scores\"]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences_en</th>\n",
       "      <th>sentences_ge</th>\n",
       "      <th>scores</th>\n",
       "      <th>person</th>\n",
       "      <th>sentences_en_no_propnouns</th>\n",
       "      <th>sentences_ge_no_propnouns</th>\n",
       "      <th>sentences_en_clean</th>\n",
       "      <th>sentences_ge_clean</th>\n",
       "      <th>non_translated_words</th>\n",
       "      <th>sentences_en_cleaner</th>\n",
       "      <th>sentences_ge_cleaner</th>\n",
       "      <th>sentences_en_final</th>\n",
       "      <th>sentences_ge_final</th>\n",
       "      <th>length_ge</th>\n",
       "      <th>length_en</th>\n",
       "      <th>distance</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>José Ortega y Gasset visited Husserl at Freibu...</td>\n",
       "      <td>1934 besuchte José Ortega y Gasset Husserl in ...</td>\n",
       "      <td>1.101697</td>\n",
       "      <td>[José Ortega y Gasset, Husserl, Freiburg]</td>\n",
       "      <td>visited  at  in 1934.</td>\n",
       "      <td>1934 besuchte   in .</td>\n",
       "      <td>visited at in</td>\n",
       "      <td>besuchte in</td>\n",
       "      <td>0</td>\n",
       "      <td>visited</td>\n",
       "      <td>besuchte</td>\n",
       "      <td>visited</td>\n",
       "      <td>besuchte</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.518761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>However, a disappointing ninth in China meant ...</td>\n",
       "      <td>Eine enttäuschende Neunte in China bedeutete j...</td>\n",
       "      <td>-0.516656</td>\n",
       "      <td>[China]</td>\n",
       "      <td>However, a disappointing ninth in  meant that ...</td>\n",
       "      <td>Eine enttäuschende Neunte in  bedeutete jedoch...</td>\n",
       "      <td>however a disappointing ninth in meant that he...</td>\n",
       "      <td>eine enttäuschende neunte in bedeutete jedoch ...</td>\n",
       "      <td>0</td>\n",
       "      <td>however disappointing ninth meant dropped back...</td>\n",
       "      <td>enttäuschende neunte bedeutete jedoch gesamtwe...</td>\n",
       "      <td>however disappointing ninth meant dropped back...</td>\n",
       "      <td>enttäuschende neunte bedeutete jedoch gesamtwe...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.619618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In his diary, Chase wrote that the release of ...</td>\n",
       "      <td>In seinem Tagebuch, Chase schrieb, dass die Ve...</td>\n",
       "      <td>-2.226388</td>\n",
       "      <td>[Chase, Mason, Slidell]</td>\n",
       "      <td>In his diary,  wrote that the release of  and ...</td>\n",
       "      <td>In seinem Tagebuch,  schrieb, dass die Veröffe...</td>\n",
       "      <td>in his diary wrote that the release of and was...</td>\n",
       "      <td>in seinem tagebuch schrieb dass die veröffentl...</td>\n",
       "      <td>0</td>\n",
       "      <td>diary wrote release like gall wormwood</td>\n",
       "      <td>tagebuch schrieb veröffentlichung galle wermut</td>\n",
       "      <td>diary wrote release like gall wormwood</td>\n",
       "      <td>tagebuch schrieb veröffentlichung galle wermut</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.633080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Heavy arquebuses mounted on wagons were called...</td>\n",
       "      <td>Schwere Arquebuses auf Waggons montiert wurden...</td>\n",
       "      <td>-0.827379</td>\n",
       "      <td>[]</td>\n",
       "      <td>Heavy arquebuses mounted on wagons were called...</td>\n",
       "      <td>Schwere Arquebuses auf Waggons montiert wurden...</td>\n",
       "      <td>heavy arquebuses mounted on wagons were called...</td>\n",
       "      <td>schwere arquebuses auf waggons montiert wurden...</td>\n",
       "      <td>4</td>\n",
       "      <td>heavy mounted wagons called</td>\n",
       "      <td>schwere waggons montiert wurden genannt</td>\n",
       "      <td>heavy mounted wagons called</td>\n",
       "      <td>schwere waggons montiert wurden genannt</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.626568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Once North Pacific salmon die off after spawni...</td>\n",
       "      <td>Sobald der nordpazifische Lachs nach dem Laich...</td>\n",
       "      <td>0.364695</td>\n",
       "      <td>[]</td>\n",
       "      <td>Once North Pacific salmon die off after spawni...</td>\n",
       "      <td>Sobald der nordpazifische Lachs nach dem Laich...</td>\n",
       "      <td>once north pacific salmon die off after spawni...</td>\n",
       "      <td>sobald der nordpazifische lachs nach dem laich...</td>\n",
       "      <td>0</td>\n",
       "      <td>north pacific salmon die spawning usually loca...</td>\n",
       "      <td>sobald nordpazifische lachs laichen abstirbt f...</td>\n",
       "      <td>north pacific salmon die spawning usually loca...</td>\n",
       "      <td>sobald lachs laichen abstirbt fressen regel lo...</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0.583080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>The gang absconded with $2,000 cash in the sec...</td>\n",
       "      <td>Die Bande flüchtete mit $2.000 Bargeld in den ...</td>\n",
       "      <td>0.164712</td>\n",
       "      <td>[St. Joseph, Louisiana]</td>\n",
       "      <td>The gang absconded with $2,000 cash in the sec...</td>\n",
       "      <td>Die Bande flüchtete mit $2.000 Bargeld in den ...</td>\n",
       "      <td>the gang absconded with cash in the second rob...</td>\n",
       "      <td>die bande flüchtete mit bargeld in den zweiten...</td>\n",
       "      <td>2</td>\n",
       "      <td>gang absconded cash second robbery took shelte...</td>\n",
       "      <td>bande flüchtete bargeld zweiten raub nahm schu...</td>\n",
       "      <td>gang absconded cash second robbery took shelte...</td>\n",
       "      <td>bande flüchtete bargeld zweiten raub nahm schu...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.582558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>The Irish settlers arrives from Northern Irela...</td>\n",
       "      <td>Die irischen Siedler kommen kurz nach den Loya...</td>\n",
       "      <td>0.394755</td>\n",
       "      <td>[]</td>\n",
       "      <td>The Irish settlers arrives from Northern Irela...</td>\n",
       "      <td>Die irischen Siedler kommen kurz nach den Loya...</td>\n",
       "      <td>the irish settlers arrives from northern irela...</td>\n",
       "      <td>die irischen siedler kommen kurz nach den loya...</td>\n",
       "      <td>0</td>\n",
       "      <td>irish settlers arrives northern ireland shortl...</td>\n",
       "      <td>irischen siedler kommen kurz loyalisten nordir...</td>\n",
       "      <td>irish settlers arrives northern ireland shortl...</td>\n",
       "      <td>irischen siedler kommen kurz loyalisten nordir...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.684928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>Volcanics include dacite breccia and small rem...</td>\n",
       "      <td>Zu den Vulkanen gehören Dacite Breccia und kle...</td>\n",
       "      <td>0.241944</td>\n",
       "      <td>[]</td>\n",
       "      <td>Volcanics include dacite breccia and small rem...</td>\n",
       "      <td>Zu den Vulkanen gehören Dacite Breccia und kle...</td>\n",
       "      <td>volcanics include dacite breccia and small rem...</td>\n",
       "      <td>zu den vulkanen gehören dacite breccia und kle...</td>\n",
       "      <td>3</td>\n",
       "      <td>volcanics include small remnants hornblende la...</td>\n",
       "      <td>vulkanen gehören kleine reste hornblende lavas...</td>\n",
       "      <td>volcanics include small remnants hornblende la...</td>\n",
       "      <td>vulkanen gehören kleine reste hornblende lavas...</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.585751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>The Fort Concho Museum acquired the Schoolhous...</td>\n",
       "      <td>Das Fort Concho Museum erwarb 1946 das Schulha...</td>\n",
       "      <td>0.360707</td>\n",
       "      <td>[Fort Concho Museum]</td>\n",
       "      <td>The  acquired the Schoolhouse in 1946 and rest...</td>\n",
       "      <td>Das  erwarb 1946 das Schulhaus und restauriert...</td>\n",
       "      <td>the acquired the schoolhouse in and restored it</td>\n",
       "      <td>das erwarb das schulhaus und restaurierte es</td>\n",
       "      <td>0</td>\n",
       "      <td>acquired schoolhouse restored</td>\n",
       "      <td>erwarb schulhaus restaurierte</td>\n",
       "      <td>acquired schoolhouse restored</td>\n",
       "      <td>erwarb schulhaus restaurierte</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.659042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>Motor lorries caked with dust, also drove west...</td>\n",
       "      <td>Motorlastwagen mit Staub verkleidet, fuhr auch...</td>\n",
       "      <td>0.214115</td>\n",
       "      <td>[]</td>\n",
       "      <td>Motor lorries caked with dust, also drove west...</td>\n",
       "      <td>Motorlastwagen mit Staub verkleidet, fuhr auch...</td>\n",
       "      <td>motor lorries caked with dust also drove westw...</td>\n",
       "      <td>motorlastwagen mit staub verkleidet fuhr auch ...</td>\n",
       "      <td>0</td>\n",
       "      <td>motor lorries caked dust also drove westwards ...</td>\n",
       "      <td>motor lastwagen staub verkleidet fuhr westen s...</td>\n",
       "      <td>motor lorries caked dust also drove westwards ...</td>\n",
       "      <td>motor lastwagen staub verkleidet fuhr westen s...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.637429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences_en  \\\n",
       "0     José Ortega y Gasset visited Husserl at Freibu...   \n",
       "1     However, a disappointing ninth in China meant ...   \n",
       "2     In his diary, Chase wrote that the release of ...   \n",
       "3     Heavy arquebuses mounted on wagons were called...   \n",
       "4     Once North Pacific salmon die off after spawni...   \n",
       "...                                                 ...   \n",
       "7995  The gang absconded with $2,000 cash in the sec...   \n",
       "7996  The Irish settlers arrives from Northern Irela...   \n",
       "7997  Volcanics include dacite breccia and small rem...   \n",
       "7998  The Fort Concho Museum acquired the Schoolhous...   \n",
       "7999  Motor lorries caked with dust, also drove west...   \n",
       "\n",
       "                                           sentences_ge    scores  \\\n",
       "0     1934 besuchte José Ortega y Gasset Husserl in ...  1.101697   \n",
       "1     Eine enttäuschende Neunte in China bedeutete j... -0.516656   \n",
       "2     In seinem Tagebuch, Chase schrieb, dass die Ve... -2.226388   \n",
       "3     Schwere Arquebuses auf Waggons montiert wurden... -0.827379   \n",
       "4     Sobald der nordpazifische Lachs nach dem Laich...  0.364695   \n",
       "...                                                 ...       ...   \n",
       "7995  Die Bande flüchtete mit $2.000 Bargeld in den ...  0.164712   \n",
       "7996  Die irischen Siedler kommen kurz nach den Loya...  0.394755   \n",
       "7997  Zu den Vulkanen gehören Dacite Breccia und kle...  0.241944   \n",
       "7998  Das Fort Concho Museum erwarb 1946 das Schulha...  0.360707   \n",
       "7999  Motorlastwagen mit Staub verkleidet, fuhr auch...  0.214115   \n",
       "\n",
       "                                         person  \\\n",
       "0     [José Ortega y Gasset, Husserl, Freiburg]   \n",
       "1                                       [China]   \n",
       "2                       [Chase, Mason, Slidell]   \n",
       "3                                            []   \n",
       "4                                            []   \n",
       "...                                         ...   \n",
       "7995                    [St. Joseph, Louisiana]   \n",
       "7996                                         []   \n",
       "7997                                         []   \n",
       "7998                       [Fort Concho Museum]   \n",
       "7999                                         []   \n",
       "\n",
       "                              sentences_en_no_propnouns  \\\n",
       "0                                 visited  at  in 1934.   \n",
       "1     However, a disappointing ninth in  meant that ...   \n",
       "2     In his diary,  wrote that the release of  and ...   \n",
       "3     Heavy arquebuses mounted on wagons were called...   \n",
       "4     Once North Pacific salmon die off after spawni...   \n",
       "...                                                 ...   \n",
       "7995  The gang absconded with $2,000 cash in the sec...   \n",
       "7996  The Irish settlers arrives from Northern Irela...   \n",
       "7997  Volcanics include dacite breccia and small rem...   \n",
       "7998  The  acquired the Schoolhouse in 1946 and rest...   \n",
       "7999  Motor lorries caked with dust, also drove west...   \n",
       "\n",
       "                              sentences_ge_no_propnouns  \\\n",
       "0                                  1934 besuchte   in .   \n",
       "1     Eine enttäuschende Neunte in  bedeutete jedoch...   \n",
       "2     In seinem Tagebuch,  schrieb, dass die Veröffe...   \n",
       "3     Schwere Arquebuses auf Waggons montiert wurden...   \n",
       "4     Sobald der nordpazifische Lachs nach dem Laich...   \n",
       "...                                                 ...   \n",
       "7995  Die Bande flüchtete mit $2.000 Bargeld in den ...   \n",
       "7996  Die irischen Siedler kommen kurz nach den Loya...   \n",
       "7997  Zu den Vulkanen gehören Dacite Breccia und kle...   \n",
       "7998  Das  erwarb 1946 das Schulhaus und restauriert...   \n",
       "7999  Motorlastwagen mit Staub verkleidet, fuhr auch...   \n",
       "\n",
       "                                     sentences_en_clean  \\\n",
       "0                                         visited at in   \n",
       "1     however a disappointing ninth in meant that he...   \n",
       "2     in his diary wrote that the release of and was...   \n",
       "3     heavy arquebuses mounted on wagons were called...   \n",
       "4     once north pacific salmon die off after spawni...   \n",
       "...                                                 ...   \n",
       "7995  the gang absconded with cash in the second rob...   \n",
       "7996  the irish settlers arrives from northern irela...   \n",
       "7997  volcanics include dacite breccia and small rem...   \n",
       "7998    the acquired the schoolhouse in and restored it   \n",
       "7999  motor lorries caked with dust also drove westw...   \n",
       "\n",
       "                                     sentences_ge_clean  non_translated_words  \\\n",
       "0                                           besuchte in                     0   \n",
       "1     eine enttäuschende neunte in bedeutete jedoch ...                     0   \n",
       "2     in seinem tagebuch schrieb dass die veröffentl...                     0   \n",
       "3     schwere arquebuses auf waggons montiert wurden...                     4   \n",
       "4     sobald der nordpazifische lachs nach dem laich...                     0   \n",
       "...                                                 ...                   ...   \n",
       "7995  die bande flüchtete mit bargeld in den zweiten...                     2   \n",
       "7996  die irischen siedler kommen kurz nach den loya...                     0   \n",
       "7997  zu den vulkanen gehören dacite breccia und kle...                     3   \n",
       "7998       das erwarb das schulhaus und restaurierte es                     0   \n",
       "7999  motorlastwagen mit staub verkleidet fuhr auch ...                     0   \n",
       "\n",
       "                                   sentences_en_cleaner  \\\n",
       "0                                               visited   \n",
       "1     however disappointing ninth meant dropped back...   \n",
       "2                diary wrote release like gall wormwood   \n",
       "3                           heavy mounted wagons called   \n",
       "4     north pacific salmon die spawning usually loca...   \n",
       "...                                                 ...   \n",
       "7995  gang absconded cash second robbery took shelte...   \n",
       "7996  irish settlers arrives northern ireland shortl...   \n",
       "7997  volcanics include small remnants hornblende la...   \n",
       "7998                      acquired schoolhouse restored   \n",
       "7999  motor lorries caked dust also drove westwards ...   \n",
       "\n",
       "                                   sentences_ge_cleaner  \\\n",
       "0                                              besuchte   \n",
       "1     enttäuschende neunte bedeutete jedoch gesamtwe...   \n",
       "2        tagebuch schrieb veröffentlichung galle wermut   \n",
       "3               schwere waggons montiert wurden genannt   \n",
       "4     sobald nordpazifische lachs laichen abstirbt f...   \n",
       "...                                                 ...   \n",
       "7995  bande flüchtete bargeld zweiten raub nahm schu...   \n",
       "7996  irischen siedler kommen kurz loyalisten nordir...   \n",
       "7997  vulkanen gehören kleine reste hornblende lavas...   \n",
       "7998                      erwarb schulhaus restaurierte   \n",
       "7999  motor lastwagen staub verkleidet fuhr westen s...   \n",
       "\n",
       "                                     sentences_en_final  \\\n",
       "0                                               visited   \n",
       "1     however disappointing ninth meant dropped back...   \n",
       "2                diary wrote release like gall wormwood   \n",
       "3                           heavy mounted wagons called   \n",
       "4     north pacific salmon die spawning usually loca...   \n",
       "...                                                 ...   \n",
       "7995  gang absconded cash second robbery took shelte...   \n",
       "7996  irish settlers arrives northern ireland shortl...   \n",
       "7997  volcanics include small remnants hornblende la...   \n",
       "7998                      acquired schoolhouse restored   \n",
       "7999  motor lorries caked dust also drove westwards ...   \n",
       "\n",
       "                                     sentences_ge_final  length_ge  length_en  \\\n",
       "0                                              besuchte          1          1   \n",
       "1     enttäuschende neunte bedeutete jedoch gesamtwe...          8          8   \n",
       "2        tagebuch schrieb veröffentlichung galle wermut          5          6   \n",
       "3               schwere waggons montiert wurden genannt          5          4   \n",
       "4     sobald lachs laichen abstirbt fressen regel lo...         11         14   \n",
       "...                                                 ...        ...        ...   \n",
       "7995  bande flüchtete bargeld zweiten raub nahm schu...         10         10   \n",
       "7996  irischen siedler kommen kurz loyalisten nordir...          6          7   \n",
       "7997  vulkanen gehören kleine reste hornblende lavas...          9         11   \n",
       "7998                      erwarb schulhaus restaurierte          3          3   \n",
       "7999  motor lastwagen staub verkleidet fuhr westen s...          8         11   \n",
       "\n",
       "      distance  correlation  \n",
       "0            0     0.518761  \n",
       "1            0     0.619618  \n",
       "2            1     0.633080  \n",
       "3           -1     0.626568  \n",
       "4            3     0.583080  \n",
       "...        ...          ...  \n",
       "7995         0     0.582558  \n",
       "7996         1     0.684928  \n",
       "7997         2     0.585751  \n",
       "7998         0     0.659042  \n",
       "7999         3     0.637429  \n",
       "\n",
       "[8000 rows x 17 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_pickle('../data/dataset_correlations_v1.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
