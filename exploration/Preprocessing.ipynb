{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing pipeline\n",
    "\n",
    "- index of sentences\n",
    "- full english sentence (without preprocessing)\n",
    "- full german sentence  (without preprocessing)\n",
    "- english sentnece no stop words, punctuation\n",
    "- german sentnece no stop words, punctuation\n",
    "- score\n",
    "- verbs in english (separated by a space and lemmatized)\n",
    "- verbs in german (separated by a space and lemmatized)\n",
    "- adjectives in english (separated by a space and lemmatized)\n",
    "- adjectives in german (separated by a space and lemmatized)\n",
    "- common nouns in english (separated by a space and lemmatized)\n",
    "- common nouns in german (separated by a space and lemmatized)\n",
    "- Nouns of persons\n",
    "- Entities or organizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp_en = spacy.load(\"en_core_web_md\")\n",
    "# nlp_ge = spacy.load(\"de_core_news_md\")\n",
    "\n",
    "import en_core_web_md\n",
    "import de_core_news_md\n",
    "nlp_en = en_core_web_md.load()\n",
    "nlp_ge = de_core_news_md.load()\n",
    "\n",
    "def spacy_analysis(sentence,nlp):\n",
    "    doc = nlp(sentence)\n",
    "    for token in doc:\n",
    "        print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "              token.shape_, token.is_alpha, token.is_stop,token.vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "# some helper functions\n",
    "def prepare_data(filename):\n",
    "    data = [l.strip().split() + ['</s>'] for l in open(filename) if l.strip()]\n",
    "    corpus = flatten(data)\n",
    "    vocab = set(corpus)\n",
    "    return vocab, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentences(filename,lower=False):\n",
    "    if lower:\n",
    "        data = [l.lower().strip() for l in open(filename) if l.strip()]\n",
    "    else:\n",
    "        data = [l.strip() for l in open(filename) if l.strip()]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences_en = pd.DataFrame(extract_sentences('../data/en_de/train.ende.src'),columns = ['sentences_en'])\n",
    "# sentences_ge = pd.DataFrame(extract_sentences('../data/en_de/train.ende.mt'),columns = ['sentences_ge'])\n",
    "# scores = pd.read_csv('../data/en_de/train.ende.scores',header=None)\n",
    "# scores = scores.rename(columns={0:\"scores\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = pd.merge(sentences_en,sentences_ge,left_index=True,right_index=True)\n",
    "# dataset = pd.merge(dataset,scores,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets ie also validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_en = os.path.join(os.path.dirname(os.getcwd()), 'data', 'en-de', 'train.ende.src')\n",
    "path_train_ge = os.path.join(os.path.dirname(os.getcwd()), 'data', 'en-de', 'train.ende.mt')\n",
    "path_train_scores = os.path.join(os.path.dirname(os.getcwd()), 'data', 'en-de', 'train.ende.scores')\n",
    "\n",
    "train_sentences_en = pd.DataFrame(extract_sentences(path_train_en),columns = ['sentences_en'])\n",
    "train_sentences_ge = pd.DataFrame(extract_sentences(path_train_ge),columns = ['sentences_ge'])\n",
    "train_scores = pd.read_csv(path_train_scores,header=None)\n",
    "train_scores = train_scores.rename(columns={0:\"scores\"})\n",
    "\n",
    "train_dataset = pd.merge(train_sentences_en,train_sentences_ge,left_index=True,right_index=True)\n",
    "train_dataset = pd.merge(train_dataset,train_scores,left_index=True,right_index=True)\n",
    "\n",
    "path_dev_en = os.path.join(os.path.dirname(os.getcwd()), 'data', 'en-de', 'dev.ende.src')\n",
    "path_dev_ge = os.path.join(os.path.dirname(os.getcwd()), 'data', 'en-de', 'dev.ende.mt')\n",
    "path_dev_scores = os.path.join(os.path.dirname(os.getcwd()), 'data', 'en-de', 'dev.ende.scores')\n",
    "\n",
    "dev_sentences_en = pd.DataFrame(extract_sentences(path_dev_en),columns = ['sentences_en'])\n",
    "dev_sentences_ge = pd.DataFrame(extract_sentences(path_dev_ge),columns = ['sentences_ge'])\n",
    "dev_scores = pd.read_csv(path_dev_scores,header=None)\n",
    "dev_scores = dev_scores.rename(columns={0:\"scores\"})\n",
    "\n",
    "dev_dataset = pd.merge(dev_sentences_en,dev_sentences_ge,left_index=True,right_index=True)\n",
    "dev_dataset = pd.merge(dev_dataset,dev_scores,left_index=True,right_index=True)\n",
    "\n",
    "dataset = pd.concat([train_dataset, dev_dataset])\n",
    "dataset = dataset.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_length(sentence):\n",
    "    leng=0\n",
    "    sentence=sentence.split(\" \")\n",
    "    for token in sentence:\n",
    "        leng+=1\n",
    "    return leng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_length(a, b):\n",
    "    lenga=0\n",
    "    a=a.split(\" \")\n",
    "    for token in a:\n",
    "        lenga+=1\n",
    "    \n",
    "    lengb=0\n",
    "    b=b.split(\" \")\n",
    "    for token in b:\n",
    "        lengb+=1\n",
    "    \n",
    "    return abs(lenga-lengb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['english_sentence_length'] = dataset['sentences_en'].apply(sentence_length)\n",
    "dataset['german_sentence_length'] = dataset['sentences_ge'].apply(sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['sentence_length_difference'] = dataset['english_sentence_length'] - dataset['german_sentence_length']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pos(pos,sentence,nlp):\n",
    "    doc = nlp(sentence)\n",
    "    res = \"\"\n",
    "    for token in doc:\n",
    "        if token.pos_==pos:\n",
    "            res += token.text + \" \"\n",
    "    res = res.strip()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[\"german_verbs\"] = dataset.sentences_ge.apply(lambda x:extract_pos(\"VERB\",x,nlp_ge))\n",
    "# dataset[\"english_verbs\"] = dataset.sentences_en.apply(lambda x:extract_pos(\"VERB\",x,nlp_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset['verbs_diff'] = dataset.apply(lambda row: difference_length(row['english_verbs'], row['german_verbs']),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[\"german_adjectives\"] = dataset.sentences_ge.apply(lambda x:extract_pos(\"ADJ\",x,nlp_ge))\n",
    "# dataset[\"english_adjectives\"] = dataset.sentences_en.apply(lambda x:extract_pos(\"ADJ\",x,nlp_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset['adjectives_diff'] = dataset.apply(lambda row: difference_length(row['english_adjectives'], row['german_adjectives']),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add adverbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[\"german_adverbs\"] = dataset.sentences_ge.apply(lambda x:extract_pos(\"ADV\",x,nlp_ge))\n",
    "# dataset[\"english_adverbs\"] = dataset.sentences_en.apply(lambda x:extract_pos(\"ADV\",x,nlp_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset['adverbs_diff'] = dataset.apply(lambda row: difference_length(row['english_adverbs'], row['german_adverbs']),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[\"german_nouns\"] = dataset.sentences_ge.apply(lambda x:extract_pos(\"NOUN\",x,nlp_ge))\n",
    "# dataset[\"english_nouns\"] = dataset.sentences_en.apply(lambda x:extract_pos(\"NOUN\",x,nlp_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset['nouns_diff'] = dataset.apply(lambda row: difference_length(row['english_nouns'], row['german_nouns']),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(sentence, nlp):\n",
    "    sentence=nlp(sentence)\n",
    "    no_punct_sentence = \"\"\n",
    "    for token in sentence:\n",
    "        if not token.is_punct:\n",
    "            no_punct_sentence+= (token.text + \" \")\n",
    "    \n",
    "    no_punct_sentence=no_punct_sentence.strip()\n",
    "    return no_punct_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset['english_no_punctuation'] = dataset['sentences_en'].apply(lambda x: remove_punct(x, nlp_en))\n",
    "# dataset['german_no_punctuation'] = dataset['sentences_ge'].apply(lambda x: remove_punct(x, nlp_ge))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS as sw_en\n",
    "from spacy.lang.de.stop_words import STOP_WORDS as sw_ge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_sw(sentence, nlp):\n",
    "    sentence = nlp(sentence)\n",
    "    no_sw_sentence = \"\"\n",
    "    \n",
    "    if nlp==nlp_en:\n",
    "        stop_words=sw_en\n",
    "    elif nlp==nlp_ge:\n",
    "        stop_words=sw_ge\n",
    "    else:\n",
    "        return('Use valid language: en or ge')\n",
    "    for token in sentence:\n",
    "        if token.text not in stop_words:\n",
    "            no_sw_sentence += token.text + \" \"\n",
    "    \n",
    "    no_sw_sentence=no_sw_sentence.strip()\n",
    "    return no_sw_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset['english_no_stop_words'] = dataset['sentences_en'].apply(lambda x: remove_sw(x, nlp_en))\n",
    "# dataset['german_no_stop_words'] = dataset['sentences_ge'].apply(lambda x: remove_sw(x, nlp_ge))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(sentence, nlp):\n",
    "    sentence = nlp(sentence)\n",
    "    lemmatized_sentence = \"\"\n",
    "    for token in sentence:\n",
    "        lemmatized_sentence += token.lemma_ + \" \"\n",
    "    \n",
    "    lemmatized_sentence = lemmatized_sentence.strip()\n",
    "    return lemmatized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset['english_lemma'] = dataset['sentences_en'].apply (lambda x: lemmatizer(x, nlp_en))\n",
    "# dataset['german_lemma'] = dataset['sentences_ge'].apply (lambda x: lemmatizer(x, nlp_ge))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob as textblob_en\n",
    "from textblob_de import TextBlobDE as textblob_ge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(sentence, textblob):\n",
    "    text = textblob(sentence)\n",
    "    score = text.sentiment.polarity\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset['english_sentence_sentiment'] = dataset['sentences_en'].apply(lambda x: sentiment(x, textblob_en))\n",
    "# dataset['german_sentence_sentiment'] = dataset['sentences_ge'].apply(lambda x: sentiment(x, textblob_ge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset['english_sentence_lemma_sentiment'] = dataset['english_lemma'].apply(lambda x: sentiment(x, textblob_en))\n",
    "# dataset['german_sentence_lemma_sentiment'] = dataset['german_lemma'].apply(lambda x: sentiment(x, textblob_ge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stdz(data):\n",
    "    data_stdz = (data - data.mean())/data.std()\n",
    "    return data_stdz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset['std_english_sentence_sentiment']= stdz(dataset['english_sentence_sentiment'])\n",
    "# dataset['std_german_sentence_sentiment']= stdz(dataset['german_sentence_sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the maximal Sentiment per sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_lemm_english = abs(dataset['english_sentence_lemma_sentiment'])>abs(dataset['english_sentence_sentiment'])\n",
    "# mask_lemm_german = abs(dataset['german_sentence_lemma_sentiment'])>abs(dataset['german_sentence_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/theophile/anaconda3/envs/nlp/lib/python3.7/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# dataset['max_sentiment_english'] = dataset['english_sentence_sentiment']\n",
    "# dataset['max_sentiment_english'].at[mask_lemm_english] = dataset['english_sentence_lemma_sentiment'][mask_lemm_english]\n",
    "\n",
    "# dataset['max_sentiment_german']=dataset['german_sentence_sentiment']\n",
    "# dataset['max_sentiment_german'].at[mask_lemm_english] = dataset['german_sentence_lemma_sentiment'][mask_lemm_english]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset['std_max_english_sentiment']= stdz(dataset['max_sentiment_english'])\n",
    "# dataset['std_max_german_sentiment']= stdz(dataset['max_sentiment_german'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Per POS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store/load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# dataset.to_pickle('../data/dataset_v1.pickle')\n",
    "dataset = pd.read_pickle(\"../data/dataset_v1.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Work on the correlations dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_em = pd.read_pickle('../data/dataset_correlations_v1.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_em['std_correlations'] = stdz(dataset_em['correlation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_em['english_em_verbs'] = dataset_em['sentences_en_final'].apply(lambda x:extract_pos(\"VERB\",x,nlp_en))\n",
    "# dataset_em[\"german_verbs\"] = dataset_em['sentences_ge_final'].apply(lambda x:extract_pos(\"VERB\",x,nlp_ge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_em[\"german_adjectives\"] = dataset_em.sentences_ge.apply(lambda x:extract_pos(\"ADJ\",x,nlp_ge))\n",
    "# dataset_em[\"english_adjectives\"] = dataset_em.sentences_en.apply(lambda x:extract_pos(\"ADJ\",x,nlp_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_em[\"german_adverbs\"] = dataset_em.sentences_ge.apply(lambda x:extract_pos(\"ADV\",x,nlp_ge))\n",
    "# dataset_em[\"english_adverbs\"] = dataset_em.sentences_en.apply(lambda x:extract_pos(\"ADV\",x,nlp_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_em[\"german_nouns\"] = dataset_em.sentences_ge.apply(lambda x:extract_pos(\"NOUN\",x,nlp_ge))\n",
    "# dataset_em[\"english_nouns\"] = dataset_em.sentences_en.apply(lambda x:extract_pos(\"NOUN\",x,nlp_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_em['embedded_words_matched_max'] = dataset_em[['length_ge','length_en']].max(axis=1)\n",
    "# dataset_em['embedded_words_matched_min'] = dataset_em[['length_ge','length_en']].min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = dataset_em.mask((dataset_em['length_en']!=0 ) &  (dataset_em['distance']!=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index_label = dataset_em.query('length_en > 0' and 'length_ge > 0').index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_em['weights2'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_em['weights2'] = dataset_em['embedded_words_matched_min']/(dataset_em['embedded_words_matched_max'] + \n",
    "                                      dataset_em['non_translated_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_em.nsmallest(10, 'scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_em[dataset_em['weighted_corr']==0]=dataset_em['weighted_corr'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_em['weights2'] = (dataset_em['embedded_words_matched_max'] - dataset_em['embedded_words_matched_min'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_em['weights2']=dataset_em['weights2'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_em['weighted_corr2'] = dataset_em['weights2']*dataset_em['correlation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004337018189317759"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_em['weighted_corr2'].corr(dataset_em['scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences_en</th>\n",
       "      <th>sentences_ge</th>\n",
       "      <th>scores</th>\n",
       "      <th>person</th>\n",
       "      <th>sentences_en_no_propnouns</th>\n",
       "      <th>sentences_ge_no_propnouns</th>\n",
       "      <th>sentences_en_clean</th>\n",
       "      <th>sentences_ge_clean</th>\n",
       "      <th>non_translated_words</th>\n",
       "      <th>sentences_en_cleaner</th>\n",
       "      <th>...</th>\n",
       "      <th>sentences_en_final</th>\n",
       "      <th>sentences_ge_final</th>\n",
       "      <th>length_ge</th>\n",
       "      <th>length_en</th>\n",
       "      <th>distance</th>\n",
       "      <th>correlation</th>\n",
       "      <th>embedded_words_matched_max</th>\n",
       "      <th>embedded_words_matched_min</th>\n",
       "      <th>weights</th>\n",
       "      <th>weighted_corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>José Ortega y Gasset visited Husserl at Freibu...</td>\n",
       "      <td>1934 besuchte José Ortega y Gasset Husserl in ...</td>\n",
       "      <td>1.101697</td>\n",
       "      <td>[José Ortega y Gasset, Husserl, Freiburg]</td>\n",
       "      <td>visited  at  in 1934.</td>\n",
       "      <td>1934 besuchte   in .</td>\n",
       "      <td>visited at in</td>\n",
       "      <td>besuchte in</td>\n",
       "      <td>0.0</td>\n",
       "      <td>visited</td>\n",
       "      <td>...</td>\n",
       "      <td>visited</td>\n",
       "      <td>besuchte</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.518761</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.518761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>However, a disappointing ninth in China meant ...</td>\n",
       "      <td>Eine enttäuschende Neunte in China bedeutete j...</td>\n",
       "      <td>-0.516656</td>\n",
       "      <td>[China]</td>\n",
       "      <td>However, a disappointing ninth in  meant that ...</td>\n",
       "      <td>Eine enttäuschende Neunte in  bedeutete jedoch...</td>\n",
       "      <td>however a disappointing ninth in meant that he...</td>\n",
       "      <td>eine enttäuschende neunte in bedeutete jedoch ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>however disappointing ninth meant dropped back...</td>\n",
       "      <td>...</td>\n",
       "      <td>however disappointing ninth meant dropped back...</td>\n",
       "      <td>enttäuschende neunte bedeutete jedoch gesamtwe...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.619618</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.619618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In his diary, Chase wrote that the release of ...</td>\n",
       "      <td>In seinem Tagebuch, Chase schrieb, dass die Ve...</td>\n",
       "      <td>-2.226388</td>\n",
       "      <td>[Chase, Mason, Slidell]</td>\n",
       "      <td>In his diary,  wrote that the release of  and ...</td>\n",
       "      <td>In seinem Tagebuch,  schrieb, dass die Veröffe...</td>\n",
       "      <td>in his diary wrote that the release of and was...</td>\n",
       "      <td>in seinem tagebuch schrieb dass die veröffentl...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>diary wrote release like gall wormwood</td>\n",
       "      <td>...</td>\n",
       "      <td>diary wrote release like gall wormwood</td>\n",
       "      <td>tagebuch schrieb veröffentlichung galle wermut</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.633080</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.527567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Heavy arquebuses mounted on wagons were called...</td>\n",
       "      <td>Schwere Arquebuses auf Waggons montiert wurden...</td>\n",
       "      <td>-0.827379</td>\n",
       "      <td>[]</td>\n",
       "      <td>Heavy arquebuses mounted on wagons were called...</td>\n",
       "      <td>Schwere Arquebuses auf Waggons montiert wurden...</td>\n",
       "      <td>heavy arquebuses mounted on wagons were called...</td>\n",
       "      <td>schwere arquebuses auf waggons montiert wurden...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>heavy mounted wagons called</td>\n",
       "      <td>...</td>\n",
       "      <td>heavy mounted wagons called</td>\n",
       "      <td>schwere waggons montiert wurden genannt</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.626568</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.278475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Once North Pacific salmon die off after spawni...</td>\n",
       "      <td>Sobald der nordpazifische Lachs nach dem Laich...</td>\n",
       "      <td>0.364695</td>\n",
       "      <td>[]</td>\n",
       "      <td>Once North Pacific salmon die off after spawni...</td>\n",
       "      <td>Sobald der nordpazifische Lachs nach dem Laich...</td>\n",
       "      <td>once north pacific salmon die off after spawni...</td>\n",
       "      <td>sobald der nordpazifische lachs nach dem laich...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>north pacific salmon die spawning usually loca...</td>\n",
       "      <td>...</td>\n",
       "      <td>north pacific salmon die spawning usually loca...</td>\n",
       "      <td>sobald lachs laichen abstirbt fressen regel lo...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.583080</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.458134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>The gang absconded with $2,000 cash in the sec...</td>\n",
       "      <td>Die Bande flüchtete mit $2.000 Bargeld in den ...</td>\n",
       "      <td>0.164712</td>\n",
       "      <td>[St. Joseph, Louisiana]</td>\n",
       "      <td>The gang absconded with $2,000 cash in the sec...</td>\n",
       "      <td>Die Bande flüchtete mit $2.000 Bargeld in den ...</td>\n",
       "      <td>the gang absconded with cash in the second rob...</td>\n",
       "      <td>die bande flüchtete mit bargeld in den zweiten...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>gang absconded cash second robbery took shelte...</td>\n",
       "      <td>...</td>\n",
       "      <td>gang absconded cash second robbery took shelte...</td>\n",
       "      <td>bande flüchtete bargeld zweiten raub nahm schu...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.582558</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.485465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>The Irish settlers arrives from Northern Irela...</td>\n",
       "      <td>Die irischen Siedler kommen kurz nach den Loya...</td>\n",
       "      <td>0.394755</td>\n",
       "      <td>[]</td>\n",
       "      <td>The Irish settlers arrives from Northern Irela...</td>\n",
       "      <td>Die irischen Siedler kommen kurz nach den Loya...</td>\n",
       "      <td>the irish settlers arrives from northern irela...</td>\n",
       "      <td>die irischen siedler kommen kurz nach den loya...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>irish settlers arrives northern ireland shortl...</td>\n",
       "      <td>...</td>\n",
       "      <td>irish settlers arrives northern ireland shortl...</td>\n",
       "      <td>irischen siedler kommen kurz loyalisten nordir...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.684928</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.587081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>Volcanics include dacite breccia and small rem...</td>\n",
       "      <td>Zu den Vulkanen gehören Dacite Breccia und kle...</td>\n",
       "      <td>0.241944</td>\n",
       "      <td>[]</td>\n",
       "      <td>Volcanics include dacite breccia and small rem...</td>\n",
       "      <td>Zu den Vulkanen gehören Dacite Breccia und kle...</td>\n",
       "      <td>volcanics include dacite breccia and small rem...</td>\n",
       "      <td>zu den vulkanen gehören dacite breccia und kle...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>volcanics include small remnants hornblende la...</td>\n",
       "      <td>...</td>\n",
       "      <td>volcanics include small remnants hornblende la...</td>\n",
       "      <td>vulkanen gehören kleine reste hornblende lavas...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.585751</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.376554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>The Fort Concho Museum acquired the Schoolhous...</td>\n",
       "      <td>Das Fort Concho Museum erwarb 1946 das Schulha...</td>\n",
       "      <td>0.360707</td>\n",
       "      <td>[Fort Concho Museum]</td>\n",
       "      <td>The  acquired the Schoolhouse in 1946 and rest...</td>\n",
       "      <td>Das  erwarb 1946 das Schulhaus und restauriert...</td>\n",
       "      <td>the acquired the schoolhouse in and restored it</td>\n",
       "      <td>das erwarb das schulhaus und restaurierte es</td>\n",
       "      <td>0.0</td>\n",
       "      <td>acquired schoolhouse restored</td>\n",
       "      <td>...</td>\n",
       "      <td>acquired schoolhouse restored</td>\n",
       "      <td>erwarb schulhaus restaurierte</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.659042</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.659042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>Motor lorries caked with dust, also drove west...</td>\n",
       "      <td>Motorlastwagen mit Staub verkleidet, fuhr auch...</td>\n",
       "      <td>0.214115</td>\n",
       "      <td>[]</td>\n",
       "      <td>Motor lorries caked with dust, also drove west...</td>\n",
       "      <td>Motorlastwagen mit Staub verkleidet, fuhr auch...</td>\n",
       "      <td>motor lorries caked with dust also drove westw...</td>\n",
       "      <td>motorlastwagen mit staub verkleidet fuhr auch ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motor lorries caked dust also drove westwards ...</td>\n",
       "      <td>...</td>\n",
       "      <td>motor lorries caked dust also drove westwards ...</td>\n",
       "      <td>motor lastwagen staub verkleidet fuhr westen s...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.637429</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.463585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences_en  \\\n",
       "0     José Ortega y Gasset visited Husserl at Freibu...   \n",
       "1     However, a disappointing ninth in China meant ...   \n",
       "2     In his diary, Chase wrote that the release of ...   \n",
       "3     Heavy arquebuses mounted on wagons were called...   \n",
       "4     Once North Pacific salmon die off after spawni...   \n",
       "...                                                 ...   \n",
       "7995  The gang absconded with $2,000 cash in the sec...   \n",
       "7996  The Irish settlers arrives from Northern Irela...   \n",
       "7997  Volcanics include dacite breccia and small rem...   \n",
       "7998  The Fort Concho Museum acquired the Schoolhous...   \n",
       "7999  Motor lorries caked with dust, also drove west...   \n",
       "\n",
       "                                           sentences_ge    scores  \\\n",
       "0     1934 besuchte José Ortega y Gasset Husserl in ...  1.101697   \n",
       "1     Eine enttäuschende Neunte in China bedeutete j... -0.516656   \n",
       "2     In seinem Tagebuch, Chase schrieb, dass die Ve... -2.226388   \n",
       "3     Schwere Arquebuses auf Waggons montiert wurden... -0.827379   \n",
       "4     Sobald der nordpazifische Lachs nach dem Laich...  0.364695   \n",
       "...                                                 ...       ...   \n",
       "7995  Die Bande flüchtete mit $2.000 Bargeld in den ...  0.164712   \n",
       "7996  Die irischen Siedler kommen kurz nach den Loya...  0.394755   \n",
       "7997  Zu den Vulkanen gehören Dacite Breccia und kle...  0.241944   \n",
       "7998  Das Fort Concho Museum erwarb 1946 das Schulha...  0.360707   \n",
       "7999  Motorlastwagen mit Staub verkleidet, fuhr auch...  0.214115   \n",
       "\n",
       "                                         person  \\\n",
       "0     [José Ortega y Gasset, Husserl, Freiburg]   \n",
       "1                                       [China]   \n",
       "2                       [Chase, Mason, Slidell]   \n",
       "3                                            []   \n",
       "4                                            []   \n",
       "...                                         ...   \n",
       "7995                    [St. Joseph, Louisiana]   \n",
       "7996                                         []   \n",
       "7997                                         []   \n",
       "7998                       [Fort Concho Museum]   \n",
       "7999                                         []   \n",
       "\n",
       "                              sentences_en_no_propnouns  \\\n",
       "0                                 visited  at  in 1934.   \n",
       "1     However, a disappointing ninth in  meant that ...   \n",
       "2     In his diary,  wrote that the release of  and ...   \n",
       "3     Heavy arquebuses mounted on wagons were called...   \n",
       "4     Once North Pacific salmon die off after spawni...   \n",
       "...                                                 ...   \n",
       "7995  The gang absconded with $2,000 cash in the sec...   \n",
       "7996  The Irish settlers arrives from Northern Irela...   \n",
       "7997  Volcanics include dacite breccia and small rem...   \n",
       "7998  The  acquired the Schoolhouse in 1946 and rest...   \n",
       "7999  Motor lorries caked with dust, also drove west...   \n",
       "\n",
       "                              sentences_ge_no_propnouns  \\\n",
       "0                                  1934 besuchte   in .   \n",
       "1     Eine enttäuschende Neunte in  bedeutete jedoch...   \n",
       "2     In seinem Tagebuch,  schrieb, dass die Veröffe...   \n",
       "3     Schwere Arquebuses auf Waggons montiert wurden...   \n",
       "4     Sobald der nordpazifische Lachs nach dem Laich...   \n",
       "...                                                 ...   \n",
       "7995  Die Bande flüchtete mit $2.000 Bargeld in den ...   \n",
       "7996  Die irischen Siedler kommen kurz nach den Loya...   \n",
       "7997  Zu den Vulkanen gehören Dacite Breccia und kle...   \n",
       "7998  Das  erwarb 1946 das Schulhaus und restauriert...   \n",
       "7999  Motorlastwagen mit Staub verkleidet, fuhr auch...   \n",
       "\n",
       "                                     sentences_en_clean  \\\n",
       "0                                         visited at in   \n",
       "1     however a disappointing ninth in meant that he...   \n",
       "2     in his diary wrote that the release of and was...   \n",
       "3     heavy arquebuses mounted on wagons were called...   \n",
       "4     once north pacific salmon die off after spawni...   \n",
       "...                                                 ...   \n",
       "7995  the gang absconded with cash in the second rob...   \n",
       "7996  the irish settlers arrives from northern irela...   \n",
       "7997  volcanics include dacite breccia and small rem...   \n",
       "7998    the acquired the schoolhouse in and restored it   \n",
       "7999  motor lorries caked with dust also drove westw...   \n",
       "\n",
       "                                     sentences_ge_clean  non_translated_words  \\\n",
       "0                                           besuchte in                   0.0   \n",
       "1     eine enttäuschende neunte in bedeutete jedoch ...                   0.0   \n",
       "2     in seinem tagebuch schrieb dass die veröffentl...                   0.0   \n",
       "3     schwere arquebuses auf waggons montiert wurden...                   4.0   \n",
       "4     sobald der nordpazifische lachs nach dem laich...                   0.0   \n",
       "...                                                 ...                   ...   \n",
       "7995  die bande flüchtete mit bargeld in den zweiten...                   2.0   \n",
       "7996  die irischen siedler kommen kurz nach den loya...                   0.0   \n",
       "7997  zu den vulkanen gehören dacite breccia und kle...                   3.0   \n",
       "7998       das erwarb das schulhaus und restaurierte es                   0.0   \n",
       "7999  motorlastwagen mit staub verkleidet fuhr auch ...                   0.0   \n",
       "\n",
       "                                   sentences_en_cleaner  ...  \\\n",
       "0                                               visited  ...   \n",
       "1     however disappointing ninth meant dropped back...  ...   \n",
       "2                diary wrote release like gall wormwood  ...   \n",
       "3                           heavy mounted wagons called  ...   \n",
       "4     north pacific salmon die spawning usually loca...  ...   \n",
       "...                                                 ...  ...   \n",
       "7995  gang absconded cash second robbery took shelte...  ...   \n",
       "7996  irish settlers arrives northern ireland shortl...  ...   \n",
       "7997  volcanics include small remnants hornblende la...  ...   \n",
       "7998                      acquired schoolhouse restored  ...   \n",
       "7999  motor lorries caked dust also drove westwards ...  ...   \n",
       "\n",
       "                                     sentences_en_final  \\\n",
       "0                                               visited   \n",
       "1     however disappointing ninth meant dropped back...   \n",
       "2                diary wrote release like gall wormwood   \n",
       "3                           heavy mounted wagons called   \n",
       "4     north pacific salmon die spawning usually loca...   \n",
       "...                                                 ...   \n",
       "7995  gang absconded cash second robbery took shelte...   \n",
       "7996  irish settlers arrives northern ireland shortl...   \n",
       "7997  volcanics include small remnants hornblende la...   \n",
       "7998                      acquired schoolhouse restored   \n",
       "7999  motor lorries caked dust also drove westwards ...   \n",
       "\n",
       "                                     sentences_ge_final length_ge  length_en  \\\n",
       "0                                              besuchte       1.0        1.0   \n",
       "1     enttäuschende neunte bedeutete jedoch gesamtwe...       8.0        8.0   \n",
       "2        tagebuch schrieb veröffentlichung galle wermut       5.0        6.0   \n",
       "3               schwere waggons montiert wurden genannt       5.0        4.0   \n",
       "4     sobald lachs laichen abstirbt fressen regel lo...      11.0       14.0   \n",
       "...                                                 ...       ...        ...   \n",
       "7995  bande flüchtete bargeld zweiten raub nahm schu...      10.0       10.0   \n",
       "7996  irischen siedler kommen kurz loyalisten nordir...       6.0        7.0   \n",
       "7997  vulkanen gehören kleine reste hornblende lavas...       9.0       11.0   \n",
       "7998                      erwarb schulhaus restaurierte       3.0        3.0   \n",
       "7999  motor lastwagen staub verkleidet fuhr westen s...       8.0       11.0   \n",
       "\n",
       "      distance  correlation  embedded_words_matched_max  \\\n",
       "0          0.0     0.518761                         1.0   \n",
       "1          0.0     0.619618                         8.0   \n",
       "2          1.0     0.633080                         6.0   \n",
       "3         -1.0     0.626568                         5.0   \n",
       "4          3.0     0.583080                        14.0   \n",
       "...        ...          ...                         ...   \n",
       "7995       0.0     0.582558                        10.0   \n",
       "7996       1.0     0.684928                         7.0   \n",
       "7997       2.0     0.585751                        11.0   \n",
       "7998       0.0     0.659042                         3.0   \n",
       "7999       3.0     0.637429                        11.0   \n",
       "\n",
       "      embedded_words_matched_min   weights  weighted_corr  \n",
       "0                            1.0  1.000000       0.518761  \n",
       "1                            8.0  1.000000       0.619618  \n",
       "2                            5.0  0.833333       0.527567  \n",
       "3                            4.0  0.444444       0.278475  \n",
       "4                           11.0  0.785714       0.458134  \n",
       "...                          ...       ...            ...  \n",
       "7995                        10.0  0.833333       0.485465  \n",
       "7996                         6.0  0.857143       0.587081  \n",
       "7997                         9.0  0.642857       0.376554  \n",
       "7998                         3.0  1.000000       0.659042  \n",
       "7999                         8.0  0.727273       0.463585  \n",
       "\n",
       "[8000 rows x 21 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences_en</th>\n",
       "      <th>sentences_ge</th>\n",
       "      <th>scores</th>\n",
       "      <th>person</th>\n",
       "      <th>sentences_en_no_propnouns</th>\n",
       "      <th>sentences_ge_no_propnouns</th>\n",
       "      <th>sentences_en_clean</th>\n",
       "      <th>sentences_ge_clean</th>\n",
       "      <th>non_translated_words</th>\n",
       "      <th>sentences_en_cleaner</th>\n",
       "      <th>...</th>\n",
       "      <th>length_ge</th>\n",
       "      <th>length_en</th>\n",
       "      <th>distance</th>\n",
       "      <th>correlation</th>\n",
       "      <th>embedded_words_matched_max</th>\n",
       "      <th>embedded_words_matched_min</th>\n",
       "      <th>weights</th>\n",
       "      <th>weighted_corr</th>\n",
       "      <th>weights2</th>\n",
       "      <th>weighted_corr2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3917</th>\n",
       "      <td>The Mummy, A Handbook of Egyptian Funerary Arc...</td>\n",
       "      <td>The Mummy, A Handbook of Egyptian Funerary Arc...</td>\n",
       "      <td>-8.140713</td>\n",
       "      <td>[]</td>\n",
       "      <td>The Mummy, A Handbook of Egyptian Funerary Arc...</td>\n",
       "      <td>The Mummy, A Handbook of Egyptian Funerary Arc...</td>\n",
       "      <td>the mummy a handbook of egyptian funerary arch...</td>\n",
       "      <td>the mummy a handbook of egyptian funerary arch...</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.615833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6975</th>\n",
       "      <td>He vacated the WWA Cruiserweight title in Apri...</td>\n",
       "      <td>Nach seiner Rückkehr zum WWF verließ er im Apr...</td>\n",
       "      <td>-7.481519</td>\n",
       "      <td>[WWF]</td>\n",
       "      <td>He vacated the WWA Cruiserweight title in Apri...</td>\n",
       "      <td>Nach seiner Rückkehr zum  verließ er im April ...</td>\n",
       "      <td>he vacated the wwa cruiserweight title in apri...</td>\n",
       "      <td>nach seiner rückkehr zum verließ er im april d...</td>\n",
       "      <td>2</td>\n",
       "      <td>vacated title april returning</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.587837</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.391891</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>Haroun and S.A. Mourad, Proceedings of Interna...</td>\n",
       "      <td>Haroun and S.A. Mourad, Proceedings of Interna...</td>\n",
       "      <td>-7.148534</td>\n",
       "      <td>[Haroun, S.A. Mourad, Cairo, Egypt]</td>\n",
       "      <td>and , Proceedings of International Colloquium...</td>\n",
       "      <td>and , Proceedings of International Colloquium...</td>\n",
       "      <td>and proceedings of international colloquium on...</td>\n",
       "      <td>and proceedings of international colloquium on...</td>\n",
       "      <td>1</td>\n",
       "      <td>proceedings international structural engineeri...</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.630766</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.450547</td>\n",
       "      <td>1</td>\n",
       "      <td>0.630766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6229</th>\n",
       "      <td>Boone Trails Grand Towers Gravois Trail New Ho...</td>\n",
       "      <td>Boone Trails Grand Towers Gravois Trail New Ho...</td>\n",
       "      <td>-7.028717</td>\n",
       "      <td>[Boone Trails Grand Towers Gravois Trail New H...</td>\n",
       "      <td>North Star Osage  Trailblazers  Trails Thunde...</td>\n",
       "      <td>North Star Osage  Trailblazers  Trails Thunde...</td>\n",
       "      <td>north star osage trailblazers trails thunderbird</td>\n",
       "      <td>north star osage trailblazers trails thunderbird</td>\n",
       "      <td>3</td>\n",
       "      <td>north star trails bird</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.570327</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.325901</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7033</th>\n",
       "      <td>World Encyclopedia of Police Forces and Penal ...</td>\n",
       "      <td>World Encyclopedia of Police Forces and Straal...</td>\n",
       "      <td>-7.028717</td>\n",
       "      <td>[]</td>\n",
       "      <td>World Encyclopedia of Police Forces and Penal ...</td>\n",
       "      <td>World Encyclopedia of Police Forces and Straal...</td>\n",
       "      <td>world encyclopedia of police forces and penal ...</td>\n",
       "      <td>world encyclopedia of police forces and straal...</td>\n",
       "      <td>1</td>\n",
       "      <td>world encyclopedia police penal systems</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.569677</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.379785</td>\n",
       "      <td>1</td>\n",
       "      <td>0.569677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846</th>\n",
       "      <td>Faerie Apocalypse, Jason Franks, IFWG Publishi...</td>\n",
       "      <td>Faerie Apocalypse, Jason Franks, IFWG Publishi...</td>\n",
       "      <td>-6.776486</td>\n",
       "      <td>[Faerie Apocalypse, Jason Franks, IFWG Publish...</td>\n",
       "      <td>, , .</td>\n",
       "      <td>, , .</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.615833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>Pollock, Griselda, Generations and Geographies...</td>\n",
       "      <td>Pollock, Griselda, Generations and Geographies...</td>\n",
       "      <td>-6.776486</td>\n",
       "      <td>[Pollock, Griselda, Generations and, the Visua...</td>\n",
       "      <td>Geographies in , , , 1996.</td>\n",
       "      <td>Geographies in , , , 1996.</td>\n",
       "      <td>geographies in</td>\n",
       "      <td>geographies in</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.615833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2214</th>\n",
       "      <td>Illustrated Encyclopedia of Woodworking Handto...</td>\n",
       "      <td>Illustrated Encyclopedia of Woodworking Handto...</td>\n",
       "      <td>-6.776486</td>\n",
       "      <td>[Woodworking Handtools, Instruments &amp; Devices]</td>\n",
       "      <td>Illustrated Encyclopedia of , .</td>\n",
       "      <td>Illustrated Encyclopedia of , .</td>\n",
       "      <td>illustrated encyclopedia of</td>\n",
       "      <td>illustrated encyclopedia of</td>\n",
       "      <td>1</td>\n",
       "      <td>encyclopedia</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524171</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.262085</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2576</th>\n",
       "      <td>\"The Great Reform Act of 1832 and British Demo...</td>\n",
       "      <td>\"The Great Reform Act of 1832 and British Demo...</td>\n",
       "      <td>-6.776486</td>\n",
       "      <td>[]</td>\n",
       "      <td>\"The Great Reform Act of 1832 and British Demo...</td>\n",
       "      <td>\"The Great Reform Act of 1832 and British Demo...</td>\n",
       "      <td>the great reform act of and british democratiz...</td>\n",
       "      <td>the great reform act of and british democracy</td>\n",
       "      <td>0</td>\n",
       "      <td>great reform act british democratization</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.661122</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.528898</td>\n",
       "      <td>1</td>\n",
       "      <td>0.661122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>\"Radio Birdman\", in The Trouser Press Record G...</td>\n",
       "      <td>\"Radio Birdman\", in The Hose Press Record Guid...</td>\n",
       "      <td>-6.629883</td>\n",
       "      <td>[ed]</td>\n",
       "      <td>\"Radio Birdman\", in The Trouser Press Record G...</td>\n",
       "      <td>\"Radio Birdman\", in The Hose Press Record Guid...</td>\n",
       "      <td>radio birdman in the trouser press record guide</td>\n",
       "      <td>radio birdman in the hose press record guide</td>\n",
       "      <td>2</td>\n",
       "      <td>radio trouser press guide</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.661558</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.441038</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences_en  \\\n",
       "3917  The Mummy, A Handbook of Egyptian Funerary Arc...   \n",
       "6975  He vacated the WWA Cruiserweight title in Apri...   \n",
       "2080  Haroun and S.A. Mourad, Proceedings of Interna...   \n",
       "6229  Boone Trails Grand Towers Gravois Trail New Ho...   \n",
       "7033  World Encyclopedia of Police Forces and Penal ...   \n",
       "1846  Faerie Apocalypse, Jason Franks, IFWG Publishi...   \n",
       "2163  Pollock, Griselda, Generations and Geographies...   \n",
       "2214  Illustrated Encyclopedia of Woodworking Handto...   \n",
       "2576  \"The Great Reform Act of 1832 and British Demo...   \n",
       "2500  \"Radio Birdman\", in The Trouser Press Record G...   \n",
       "\n",
       "                                           sentences_ge    scores  \\\n",
       "3917  The Mummy, A Handbook of Egyptian Funerary Arc... -8.140713   \n",
       "6975  Nach seiner Rückkehr zum WWF verließ er im Apr... -7.481519   \n",
       "2080  Haroun and S.A. Mourad, Proceedings of Interna... -7.148534   \n",
       "6229  Boone Trails Grand Towers Gravois Trail New Ho... -7.028717   \n",
       "7033  World Encyclopedia of Police Forces and Straal... -7.028717   \n",
       "1846  Faerie Apocalypse, Jason Franks, IFWG Publishi... -6.776486   \n",
       "2163  Pollock, Griselda, Generations and Geographies... -6.776486   \n",
       "2214  Illustrated Encyclopedia of Woodworking Handto... -6.776486   \n",
       "2576  \"The Great Reform Act of 1832 and British Demo... -6.776486   \n",
       "2500  \"Radio Birdman\", in The Hose Press Record Guid... -6.629883   \n",
       "\n",
       "                                                 person  \\\n",
       "3917                                                 []   \n",
       "6975                                              [WWF]   \n",
       "2080                [Haroun, S.A. Mourad, Cairo, Egypt]   \n",
       "6229  [Boone Trails Grand Towers Gravois Trail New H...   \n",
       "7033                                                 []   \n",
       "1846  [Faerie Apocalypse, Jason Franks, IFWG Publish...   \n",
       "2163  [Pollock, Griselda, Generations and, the Visua...   \n",
       "2214     [Woodworking Handtools, Instruments & Devices]   \n",
       "2576                                                 []   \n",
       "2500                                               [ed]   \n",
       "\n",
       "                              sentences_en_no_propnouns  \\\n",
       "3917  The Mummy, A Handbook of Egyptian Funerary Arc...   \n",
       "6975  He vacated the WWA Cruiserweight title in Apri...   \n",
       "2080   and , Proceedings of International Colloquium...   \n",
       "6229   North Star Osage  Trailblazers  Trails Thunde...   \n",
       "7033  World Encyclopedia of Police Forces and Penal ...   \n",
       "1846                                              , , .   \n",
       "2163                         Geographies in , , , 1996.   \n",
       "2214                    Illustrated Encyclopedia of , .   \n",
       "2576  \"The Great Reform Act of 1832 and British Demo...   \n",
       "2500  \"Radio Birdman\", in The Trouser Press Record G...   \n",
       "\n",
       "                              sentences_ge_no_propnouns  \\\n",
       "3917  The Mummy, A Handbook of Egyptian Funerary Arc...   \n",
       "6975  Nach seiner Rückkehr zum  verließ er im April ...   \n",
       "2080   and , Proceedings of International Colloquium...   \n",
       "6229   North Star Osage  Trailblazers  Trails Thunde...   \n",
       "7033  World Encyclopedia of Police Forces and Straal...   \n",
       "1846                                              , , .   \n",
       "2163                         Geographies in , , , 1996.   \n",
       "2214                    Illustrated Encyclopedia of , .   \n",
       "2576  \"The Great Reform Act of 1832 and British Demo...   \n",
       "2500  \"Radio Birdman\", in The Hose Press Record Guid...   \n",
       "\n",
       "                                     sentences_en_clean  \\\n",
       "3917  the mummy a handbook of egyptian funerary arch...   \n",
       "6975  he vacated the wwa cruiserweight title in apri...   \n",
       "2080  and proceedings of international colloquium on...   \n",
       "6229   north star osage trailblazers trails thunderbird   \n",
       "7033  world encyclopedia of police forces and penal ...   \n",
       "1846                                                      \n",
       "2163                                     geographies in   \n",
       "2214                        illustrated encyclopedia of   \n",
       "2576  the great reform act of and british democratiz...   \n",
       "2500    radio birdman in the trouser press record guide   \n",
       "\n",
       "                                     sentences_ge_clean  non_translated_words  \\\n",
       "3917  the mummy a handbook of egyptian funerary arch...                     5   \n",
       "6975  nach seiner rückkehr zum verließ er im april d...                     2   \n",
       "2080  and proceedings of international colloquium on...                     1   \n",
       "6229   north star osage trailblazers trails thunderbird                     3   \n",
       "7033  world encyclopedia of police forces and straal...                     1   \n",
       "1846                                                                        0   \n",
       "2163                                     geographies in                     1   \n",
       "2214                        illustrated encyclopedia of                     1   \n",
       "2576      the great reform act of and british democracy                     0   \n",
       "2500       radio birdman in the hose press record guide                     2   \n",
       "\n",
       "                                   sentences_en_cleaner  ... length_ge  \\\n",
       "3917                                                     ...         0   \n",
       "6975                      vacated title april returning  ...         4   \n",
       "2080  proceedings international structural engineeri...  ...         5   \n",
       "6229                             north star trails bird  ...         4   \n",
       "7033            world encyclopedia police penal systems  ...         4   \n",
       "1846                                                     ...         0   \n",
       "2163                                                     ...         0   \n",
       "2214                                       encyclopedia  ...         1   \n",
       "2576           great reform act british democratization  ...         4   \n",
       "2500                          radio trouser press guide  ...         4   \n",
       "\n",
       "     length_en distance  correlation  embedded_words_matched_max  \\\n",
       "3917         0        0     0.615833                           0   \n",
       "6975         4        0     0.587837                           4   \n",
       "2080         6        1     0.630766                           6   \n",
       "6229         4        0     0.570327                           4   \n",
       "7033         5        1     0.569677                           5   \n",
       "1846         0        0     0.615833                           0   \n",
       "2163         0        0     0.615833                           0   \n",
       "2214         1        0     0.524171                           1   \n",
       "2576         5        1     0.661122                           5   \n",
       "2500         4        0     0.661558                           4   \n",
       "\n",
       "      embedded_words_matched_min   weights  weighted_corr  weights2  \\\n",
       "3917                           0  0.000000       0.000000         0   \n",
       "6975                           4  0.666667       0.391891         0   \n",
       "2080                           5  0.714286       0.450547         1   \n",
       "6229                           4  0.571429       0.325901         0   \n",
       "7033                           4  0.666667       0.379785         1   \n",
       "1846                           0  0.000000       0.000000         0   \n",
       "2163                           0  0.000000       0.000000         0   \n",
       "2214                           1  0.500000       0.262085         0   \n",
       "2576                           4  0.800000       0.528898         1   \n",
       "2500                           4  0.666667       0.441038         0   \n",
       "\n",
       "      weighted_corr2  \n",
       "3917        0.000000  \n",
       "6975        0.000000  \n",
       "2080        0.630766  \n",
       "6229        0.000000  \n",
       "7033        0.569677  \n",
       "1846        0.000000  \n",
       "2163        0.000000  \n",
       "2214        0.000000  \n",
       "2576        0.661122  \n",
       "2500        0.000000  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_em.nsmallest(10, 'scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_em.to_pickle('../data/dataset_correlations_v2.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# dataset_em = pd.read_pickle('../data/dataset_correlations_v2.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences_en</th>\n",
       "      <th>sentences_ge</th>\n",
       "      <th>scores</th>\n",
       "      <th>person</th>\n",
       "      <th>sentences_en_no_propnouns</th>\n",
       "      <th>sentences_ge_no_propnouns</th>\n",
       "      <th>sentences_en_clean</th>\n",
       "      <th>sentences_ge_clean</th>\n",
       "      <th>non_translated_words</th>\n",
       "      <th>sentences_en_cleaner</th>\n",
       "      <th>...</th>\n",
       "      <th>sentences_en_final</th>\n",
       "      <th>sentences_ge_final</th>\n",
       "      <th>length_ge</th>\n",
       "      <th>length_en</th>\n",
       "      <th>distance</th>\n",
       "      <th>correlation</th>\n",
       "      <th>embedded_words_matched_max</th>\n",
       "      <th>embedded_words_matched_min</th>\n",
       "      <th>weights</th>\n",
       "      <th>weighted_corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>José Ortega y Gasset visited Husserl at Freibu...</td>\n",
       "      <td>1934 besuchte José Ortega y Gasset Husserl in ...</td>\n",
       "      <td>1.101697</td>\n",
       "      <td>[José Ortega y Gasset, Husserl, Freiburg]</td>\n",
       "      <td>visited  at  in 1934.</td>\n",
       "      <td>1934 besuchte   in .</td>\n",
       "      <td>visited at in</td>\n",
       "      <td>besuchte in</td>\n",
       "      <td>0</td>\n",
       "      <td>visited</td>\n",
       "      <td>...</td>\n",
       "      <td>visited</td>\n",
       "      <td>besuchte</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.518761</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.518761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>However, a disappointing ninth in China meant ...</td>\n",
       "      <td>Eine enttäuschende Neunte in China bedeutete j...</td>\n",
       "      <td>-0.516656</td>\n",
       "      <td>[China]</td>\n",
       "      <td>However, a disappointing ninth in  meant that ...</td>\n",
       "      <td>Eine enttäuschende Neunte in  bedeutete jedoch...</td>\n",
       "      <td>however a disappointing ninth in meant that he...</td>\n",
       "      <td>eine enttäuschende neunte in bedeutete jedoch ...</td>\n",
       "      <td>0</td>\n",
       "      <td>however disappointing ninth meant dropped back...</td>\n",
       "      <td>...</td>\n",
       "      <td>however disappointing ninth meant dropped back...</td>\n",
       "      <td>enttäuschende neunte bedeutete jedoch gesamtwe...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.619618</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.619618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In his diary, Chase wrote that the release of ...</td>\n",
       "      <td>In seinem Tagebuch, Chase schrieb, dass die Ve...</td>\n",
       "      <td>-2.226388</td>\n",
       "      <td>[Chase, Mason, Slidell]</td>\n",
       "      <td>In his diary,  wrote that the release of  and ...</td>\n",
       "      <td>In seinem Tagebuch,  schrieb, dass die Veröffe...</td>\n",
       "      <td>in his diary wrote that the release of and was...</td>\n",
       "      <td>in seinem tagebuch schrieb dass die veröffentl...</td>\n",
       "      <td>0</td>\n",
       "      <td>diary wrote release like gall wormwood</td>\n",
       "      <td>...</td>\n",
       "      <td>diary wrote release like gall wormwood</td>\n",
       "      <td>tagebuch schrieb veröffentlichung galle wermut</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.633080</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.527567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Heavy arquebuses mounted on wagons were called...</td>\n",
       "      <td>Schwere Arquebuses auf Waggons montiert wurden...</td>\n",
       "      <td>-0.827379</td>\n",
       "      <td>[]</td>\n",
       "      <td>Heavy arquebuses mounted on wagons were called...</td>\n",
       "      <td>Schwere Arquebuses auf Waggons montiert wurden...</td>\n",
       "      <td>heavy arquebuses mounted on wagons were called...</td>\n",
       "      <td>schwere arquebuses auf waggons montiert wurden...</td>\n",
       "      <td>4</td>\n",
       "      <td>heavy mounted wagons called</td>\n",
       "      <td>...</td>\n",
       "      <td>heavy mounted wagons called</td>\n",
       "      <td>schwere waggons montiert wurden genannt</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.626568</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.278475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Once North Pacific salmon die off after spawni...</td>\n",
       "      <td>Sobald der nordpazifische Lachs nach dem Laich...</td>\n",
       "      <td>0.364695</td>\n",
       "      <td>[]</td>\n",
       "      <td>Once North Pacific salmon die off after spawni...</td>\n",
       "      <td>Sobald der nordpazifische Lachs nach dem Laich...</td>\n",
       "      <td>once north pacific salmon die off after spawni...</td>\n",
       "      <td>sobald der nordpazifische lachs nach dem laich...</td>\n",
       "      <td>0</td>\n",
       "      <td>north pacific salmon die spawning usually loca...</td>\n",
       "      <td>...</td>\n",
       "      <td>north pacific salmon die spawning usually loca...</td>\n",
       "      <td>sobald lachs laichen abstirbt fressen regel lo...</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0.583080</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.458134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        sentences_en  \\\n",
       "0  José Ortega y Gasset visited Husserl at Freibu...   \n",
       "1  However, a disappointing ninth in China meant ...   \n",
       "2  In his diary, Chase wrote that the release of ...   \n",
       "3  Heavy arquebuses mounted on wagons were called...   \n",
       "4  Once North Pacific salmon die off after spawni...   \n",
       "\n",
       "                                        sentences_ge    scores  \\\n",
       "0  1934 besuchte José Ortega y Gasset Husserl in ...  1.101697   \n",
       "1  Eine enttäuschende Neunte in China bedeutete j... -0.516656   \n",
       "2  In seinem Tagebuch, Chase schrieb, dass die Ve... -2.226388   \n",
       "3  Schwere Arquebuses auf Waggons montiert wurden... -0.827379   \n",
       "4  Sobald der nordpazifische Lachs nach dem Laich...  0.364695   \n",
       "\n",
       "                                      person  \\\n",
       "0  [José Ortega y Gasset, Husserl, Freiburg]   \n",
       "1                                    [China]   \n",
       "2                    [Chase, Mason, Slidell]   \n",
       "3                                         []   \n",
       "4                                         []   \n",
       "\n",
       "                           sentences_en_no_propnouns  \\\n",
       "0                              visited  at  in 1934.   \n",
       "1  However, a disappointing ninth in  meant that ...   \n",
       "2  In his diary,  wrote that the release of  and ...   \n",
       "3  Heavy arquebuses mounted on wagons were called...   \n",
       "4  Once North Pacific salmon die off after spawni...   \n",
       "\n",
       "                           sentences_ge_no_propnouns  \\\n",
       "0                               1934 besuchte   in .   \n",
       "1  Eine enttäuschende Neunte in  bedeutete jedoch...   \n",
       "2  In seinem Tagebuch,  schrieb, dass die Veröffe...   \n",
       "3  Schwere Arquebuses auf Waggons montiert wurden...   \n",
       "4  Sobald der nordpazifische Lachs nach dem Laich...   \n",
       "\n",
       "                                  sentences_en_clean  \\\n",
       "0                                      visited at in   \n",
       "1  however a disappointing ninth in meant that he...   \n",
       "2  in his diary wrote that the release of and was...   \n",
       "3  heavy arquebuses mounted on wagons were called...   \n",
       "4  once north pacific salmon die off after spawni...   \n",
       "\n",
       "                                  sentences_ge_clean  non_translated_words  \\\n",
       "0                                        besuchte in                     0   \n",
       "1  eine enttäuschende neunte in bedeutete jedoch ...                     0   \n",
       "2  in seinem tagebuch schrieb dass die veröffentl...                     0   \n",
       "3  schwere arquebuses auf waggons montiert wurden...                     4   \n",
       "4  sobald der nordpazifische lachs nach dem laich...                     0   \n",
       "\n",
       "                                sentences_en_cleaner  ...  \\\n",
       "0                                            visited  ...   \n",
       "1  however disappointing ninth meant dropped back...  ...   \n",
       "2             diary wrote release like gall wormwood  ...   \n",
       "3                        heavy mounted wagons called  ...   \n",
       "4  north pacific salmon die spawning usually loca...  ...   \n",
       "\n",
       "                                  sentences_en_final  \\\n",
       "0                                            visited   \n",
       "1  however disappointing ninth meant dropped back...   \n",
       "2             diary wrote release like gall wormwood   \n",
       "3                        heavy mounted wagons called   \n",
       "4  north pacific salmon die spawning usually loca...   \n",
       "\n",
       "                                  sentences_ge_final length_ge  length_en  \\\n",
       "0                                           besuchte         1          1   \n",
       "1  enttäuschende neunte bedeutete jedoch gesamtwe...         8          8   \n",
       "2     tagebuch schrieb veröffentlichung galle wermut         5          6   \n",
       "3            schwere waggons montiert wurden genannt         5          4   \n",
       "4  sobald lachs laichen abstirbt fressen regel lo...        11         14   \n",
       "\n",
       "   distance  correlation  embedded_words_matched_max  \\\n",
       "0         0     0.518761                           1   \n",
       "1         0     0.619618                           8   \n",
       "2         1     0.633080                           6   \n",
       "3        -1     0.626568                           5   \n",
       "4         3     0.583080                          14   \n",
       "\n",
       "   embedded_words_matched_min   weights  weighted_corr  \n",
       "0                           1  1.000000       0.518761  \n",
       "1                           8  1.000000       0.619618  \n",
       "2                           5  0.833333       0.527567  \n",
       "3                           4  0.444444       0.278475  \n",
       "4                          11  0.785714       0.458134  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset_em.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
