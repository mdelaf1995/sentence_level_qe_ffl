{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from scipy.stats.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_embeddings = pd.read_pickle('../data/dataset_correlations_v1.pickle')\n",
    "dataset_embeddings = pd.read_pickle('../data/dataset_correlations_v2.pickle')\n",
    "dataset_baseline = pd.read_pickle(\"../data/dataset_v1.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sentences_en', 'sentences_ge', 'scores', 'person',\n",
       "       'sentences_en_no_propnouns', 'sentences_ge_no_propnouns',\n",
       "       'sentences_en_clean', 'sentences_ge_clean', 'non_translated_words',\n",
       "       'sentences_en_cleaner', 'sentences_ge_cleaner', 'sentences_en_final',\n",
       "       'sentences_ge_final', 'length_ge', 'length_en', 'distance',\n",
       "       'correlation', 'std_correlations'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_embeddings.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_embeddings_features = dataset_embeddings[['non_translated_words',\n",
    "                                                 'distance',\n",
    "                                                 'std_correlations']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sentences_en', 'sentences_ge', 'scores', 'english_sentence_length',\n",
       "       'german_sentence_length', 'sentence_length_difference', 'german_verbs',\n",
       "       'english_verbs', 'german_adjectives', 'english_adjectives',\n",
       "       'german_adverbs', 'english_adverbs', 'german_nouns', 'english_nouns',\n",
       "       'english_no_punctuation', 'german_no_punctuation',\n",
       "       'english_no_stop_words', 'german_no_stop_words', 'english_lemma',\n",
       "       'german_lemma', 'english_sentence_sentiment',\n",
       "       'german_sentence_sentiment', 'std_english_sentence_sentiment',\n",
       "       'std_german_sentence_sentiment', 'english_sentence_lemma_sentiment',\n",
       "       'german_sentence_lemma_sentiment', 'max_sentiment_english',\n",
       "       'max_sentiment_german', 'std_max_english_sentiment',\n",
       "       'std_max_german_sentiment', 'verbs_diff', 'adjectives_diff',\n",
       "       'adverbs_diff', 'nouns_diff'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_baseline.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_baseline_features = dataset_baseline[['std_max_english_sentiment',\n",
    "                                              'std_max_german_sentiment',\n",
    "                                              'max_sentiment_english',\n",
    "                                              'max_sentiment_german',\n",
    "                                              'sentence_length_difference',\n",
    "                                              'verbs_diff', \n",
    "                                              'adjectives_diff',\n",
    "                                              'adverbs_diff',\n",
    "                                              'nouns_diff'\n",
    "                                             ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_features = pd.concat((dataset_baseline_features, dataset_embeddings_features),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_features = dataset_features[['correlation','non_translated_words']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>std_max_english_sentiment</th>\n",
       "      <th>std_max_german_sentiment</th>\n",
       "      <th>max_sentiment_english</th>\n",
       "      <th>max_sentiment_german</th>\n",
       "      <th>sentence_length_difference</th>\n",
       "      <th>verbs_diff</th>\n",
       "      <th>adjectives_diff</th>\n",
       "      <th>adverbs_diff</th>\n",
       "      <th>nouns_diff</th>\n",
       "      <th>non_translated_words</th>\n",
       "      <th>distance</th>\n",
       "      <th>std_correlations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.186145</td>\n",
       "      <td>-0.007065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.120192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.661481</td>\n",
       "      <td>-2.422978</td>\n",
       "      <td>-0.304167</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.186145</td>\n",
       "      <td>-0.007065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.199028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.156229</td>\n",
       "      <td>-0.007065</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.123885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.186145</td>\n",
       "      <td>-0.007065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.377963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>-0.186145</td>\n",
       "      <td>-0.007065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.383984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>-0.186145</td>\n",
       "      <td>-0.007065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.797347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>-1.520010</td>\n",
       "      <td>-1.698204</td>\n",
       "      <td>-0.275000</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.347143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>-0.186145</td>\n",
       "      <td>-0.007065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.498618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>-0.186145</td>\n",
       "      <td>-0.007065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.249217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      std_max_english_sentiment  std_max_german_sentiment  \\\n",
       "0                     -0.186145                 -0.007065   \n",
       "1                     -1.661481                 -2.422978   \n",
       "2                     -0.186145                 -0.007065   \n",
       "3                     -1.156229                 -0.007065   \n",
       "4                     -0.186145                 -0.007065   \n",
       "...                         ...                       ...   \n",
       "7995                  -0.186145                 -0.007065   \n",
       "7996                  -0.186145                 -0.007065   \n",
       "7997                  -1.520010                 -1.698204   \n",
       "7998                  -0.186145                 -0.007065   \n",
       "7999                  -0.186145                 -0.007065   \n",
       "\n",
       "      max_sentiment_english  max_sentiment_german  sentence_length_difference  \\\n",
       "0                  0.000000                   0.0                           1   \n",
       "1                 -0.304167                  -1.0                          -1   \n",
       "2                  0.000000                   0.0                           0   \n",
       "3                 -0.200000                   0.0                           0   \n",
       "4                  0.000000                   0.0                           0   \n",
       "...                     ...                   ...                         ...   \n",
       "7995               0.000000                   0.0                           0   \n",
       "7996               0.000000                   0.0                           1   \n",
       "7997              -0.275000                  -0.7                          -2   \n",
       "7998               0.000000                   0.0                           1   \n",
       "7999               0.000000                   0.0                           0   \n",
       "\n",
       "      verbs_diff  adjectives_diff  adverbs_diff  nouns_diff  \\\n",
       "0              0                0             0           0   \n",
       "1              0                0             1           1   \n",
       "2              0                0             0           1   \n",
       "3              0                0             0           0   \n",
       "4              1                0             1           1   \n",
       "...          ...              ...           ...         ...   \n",
       "7995           1                2             0           3   \n",
       "7996           0                1             0           1   \n",
       "7997           2                0             0           2   \n",
       "7998           0                0             0           1   \n",
       "7999           0                0             1           0   \n",
       "\n",
       "      non_translated_words  distance  std_correlations  \n",
       "0                        0         0         -1.120192  \n",
       "1                        0         0          0.043681  \n",
       "2                        0         1          0.199028  \n",
       "3                        4        -1          0.123885  \n",
       "4                        0         3         -0.377963  \n",
       "...                    ...       ...               ...  \n",
       "7995                     2         0         -0.383984  \n",
       "7996                     0         1          0.797347  \n",
       "7997                     3         2         -0.347143  \n",
       "7998                     0         0          0.498618  \n",
       "7999                     0         3          0.249217  \n",
       "\n",
       "[8000 rows x 12 columns]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_features_list = list(dataset_features.columns)\n",
    "dataset_features_arr = np.array(dataset_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_labels = dataset_embeddings['scores']\n",
    "dataset_labels_arr = np.array(dataset_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Train and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = dataset_features_arr[:7000]\n",
    "train_labels = dataset_labels_arr[:7000]\n",
    "\n",
    "val_features = dataset_features_arr[7000:]\n",
    "val_labels = dataset_labels_arr[7000:]\n",
    "\n",
    "# train_features = np.concatenate((dataset_features_arr[:6000], dataset_features_arr[7000:]))\n",
    "# train_labels = np.concatenate((dataset_labels_arr[:6000], dataset_labels_arr[7000:]))\n",
    "\n",
    "# val_features = dataset_features_arr[6000:7000]\n",
    "# val_labels = dataset_labels_arr[6000:7000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (7000, 12)\n",
      "Training Labels Shape: (7000,)\n",
      "Testing Features Shape: (1000, 12)\n",
      "Testing Labels Shape: (1000,)\n"
     ]
    }
   ],
   "source": [
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', val_features.shape)\n",
    "print('Testing Labels Shape:', val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8603439155704071\n",
      "Pearson 0.0909183812729866\n",
      "Mean Absolute Error: 0.5216\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 666, max_depth = 2)\n",
    "rf.fit(train_features, train_labels);\n",
    "predictions = rf.predict(val_features)\n",
    "pearson = pearsonr(val_labels, predictions)\n",
    "errors = abs(predictions - val_labels)\n",
    "print('RMSE:', rmse(predictions,val_labels))\n",
    "print(f\"Pearson {pearson[0]}\")\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: std_correlations     Importance: 0.67\n",
      "Variable: non_translated_words Importance: 0.14\n",
      "Variable: distance             Importance: 0.08\n",
      "Variable: nouns_diff           Importance: 0.05\n",
      "Variable: std_max_english_sentiment Importance: 0.02\n",
      "Variable: max_sentiment_english Importance: 0.02\n",
      "Variable: sentence_length_difference Importance: 0.01\n",
      "Variable: verbs_diff           Importance: 0.01\n",
      "Variable: std_max_german_sentiment Importance: 0.0\n",
      "Variable: max_sentiment_german Importance: 0.0\n",
      "Variable: adjectives_diff      Importance: 0.0\n",
      "Variable: adverbs_diff         Importance: 0.0\n"
     ]
    }
   ],
   "source": [
    "importances = list(rf.feature_importances_)\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(dataset_features_list, importances)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear\n",
      "RMSE: 0.8765473527399004\n",
      "Pearson 0.1300191766974358\n",
      "Mean Absolute Error: 0.4876\n",
      "\n",
      "poly\n",
      "RMSE: 0.8839171969860865\n",
      "Pearson 0.03526143522827664\n",
      "Mean Absolute Error: 0.4972\n",
      "\n",
      "rbf\n",
      "RMSE: 0.8826129098984249\n",
      "Pearson 0.05280393944950446\n",
      "Mean Absolute Error: 0.5009\n",
      "\n",
      "sigmoid\n",
      "RMSE: 120.4722536598051\n",
      "Pearson 0.02583690688614004\n",
      "Mean Absolute Error: 54.2065\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in ['linear','poly','rbf','sigmoid']:\n",
    "    clf_t = SVR(kernel=k)\n",
    "    clf_t.fit(train_features, train_labels)\n",
    "    print(k)\n",
    "    predictions = clf_t.predict(val_features)\n",
    "    pearson = pearsonr(val_labels, predictions)\n",
    "    errors = abs(predictions - val_labels)\n",
    "    print(f'RMSE: {rmse(predictions,val_labels)}')\n",
    "    print(f'Pearson {pearson[0]}')\n",
    "    print('Mean Absolute Error:', round(np.mean(errors), 4))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
