{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Getting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section shows the way the built features and the scores are extracted after the sentences have been preprocessed through the 'feature_engineering_pipeline' code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_pickle('data/datasets/dataset_with_features.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the numerical features created\n",
    "features = dataset[['max_sentiment_english',\n",
    "                    'max_sentiment_german',\n",
    "                    'std_max_english_sentiment',\n",
    "                    'std_max_german_sentiment',\n",
    "                    'german_sentence_length',\n",
    "                    'english_sentence_length',\n",
    "                    'sentence_length_difference',\n",
    "                    'verbs_diff',\n",
    "                    'adjectives_diff',\n",
    "                    'adverbs_diff',\n",
    "                    'nouns_diff',\n",
    "                    'non_translated_words',\n",
    "                    'correlation',\n",
    "                    'sentence_correlation',\n",
    "                    'non_match_correlation',\n",
    "                    'non_translated_ratio']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting between the Train/Validation dataset and the test\n",
    "train_val = features[:8000]\n",
    "test = features[8000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the features to a list (used for random forest important features)\n",
    "dataset_features_list = list(train_val.columns)\n",
    "dataset_features_arr = np.array(train_val)\n",
    "test_features_arr = np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting the scores for the train and validation datasets\n",
    "path_train_scores = os.path.join(os.getcwd(), 'data', 'en-de', 'train.ende.scores')\n",
    "train_scores = pd.read_csv(path_train_scores,header=None)\n",
    "train_scores = train_scores.rename(columns={0:\"scores\"})\n",
    "path_val_scores = os.path.join(os.getcwd(), 'data', 'en-de', 'dev.ende.scores')\n",
    "val_scores = pd.read_csv(path_val_scores,header=None)\n",
    "val_scores = val_scores.rename(columns={0:\"scores\"})\n",
    "scores = pd.concat([train_scores, val_scores])\n",
    "\n",
    "dataset_labels_arr = np.array(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cross Validation and results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section shows the two step cross validation for each of the chosen algorithms: PLS, Ridge, SVM, Random Forest, Neural Networks.\n",
    "The first step consists of a randomized grid search cross validation to provide the best model parameters for each model.\n",
    "The second step consists of running 500 randomly split cross validations to estimate the distribution in scores of each of the best models. This allows to seelect the best model and then pass it through section 3 to make the test predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines to standardize the features if desired\n",
    "\n",
    "# normalised = (dataset_features_arr - dataset_features_arr.min(axis=0))/ \\\n",
    "#              (dataset_features_arr.max(axis=0) - dataset_features_arr.min(axis=0))\n",
    "# normalised.var(axis=0)\n",
    "# sel = VarianceThreshold(threshold=0.01)\n",
    "# dataset_features_arr = sel.fit_transform(normalised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 PLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing a randomized grid search and cross validation to find the best PLSRegressor model \n",
    "\n",
    "n_components = [int(x) for x in np.arange(1,12)]\n",
    "scale = [True, False]\n",
    "max_iter = [int(x) for x in np.arange(300,1000)]\n",
    "\n",
    "random_grid = {'n_components': n_components,\n",
    "               'scale': scale, \n",
    "               'max_iter':max_iter}\n",
    "\n",
    "pls = PLSRegression()\n",
    "pls_random = RandomizedSearchCV(estimator = pls, param_distributions = random_grid, \n",
    "                                n_iter = 100, cv = 8, random_state=42, scoring='neg_mean_squared_error')\n",
    "pls_random.fit(dataset_features_arr, dataset_labels_arr)\n",
    "print(pls_random.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the next cell, a cross validation over many randomly created splits are run on each of the best model to provide estimates of the score distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = ShuffleSplit(n_splits=500, test_size=.25, random_state=0)\n",
    "cv = rs.split(dataset_features_arr)\n",
    "\n",
    "correlation_pls = []\n",
    "mae_pls = []\n",
    "X = dataset_features_arr\n",
    "y = dataset_labels_arr.reshape(-1)\n",
    "\n",
    "for train, test in cv:\n",
    "    pls = PLSRegression(**pls_random.best_params_)\n",
    "    pls.fit(X[train], y[train])\n",
    "    predictions = pls.predict(X[test]).reshape(-1)\n",
    "    pearson = pearsonr(y[test], predictions)[0]\n",
    "    error = abs(predictions - y[test])\n",
    "    correlation_pls.append(pearson)\n",
    "    mae_pls.append(error)\n",
    "    \n",
    "print(np.array(correlation_pls).mean())\n",
    "print(np.array(mae_pls).mean())\n",
    "print(np.array(correlation_pls).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictions directory if don't exist\n",
    "predictions_dir = os.path.join(os.getcwd(), 'data', 'imgs')\n",
    "if not os.path.exists(predictions_dir):\n",
    "    os.mkdir(predictions_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(correlation_pls)\n",
    "plt.xlabel('Pearson Correlation')\n",
    "plt.ylabel('Counts')\n",
    "plt.savefig('data/imgs/pls.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing a randomized grid search and cross validation to find the best Ridge Linear Regression model \n",
    "\n",
    "alpha = [x for x in np.linspace(0,1,10)]\n",
    "normalize = [True, False]\n",
    "max_iter = [int(x) for x in np.arange(300,1500)]\n",
    "\n",
    "random_grid = {'alpha': alpha,\n",
    "               'normalize': normalize, \n",
    "               'max_iter':max_iter}\n",
    "\n",
    "lr = Ridge()\n",
    "lr_random = RandomizedSearchCV(estimator = lr, param_distributions = random_grid, \n",
    "                                n_iter = 100, cv = 8, random_state=42, scoring='neg_mean_squared_error')\n",
    "lr_random.fit(dataset_features_arr, dataset_labels_arr)\n",
    "print(lr_random.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the next cell, a cross validation over many randomly created splits are run on each of the best model to provide estimates of the score distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a cross validation over 500 different splits to compute an estimate of the score distribution\n",
    "\n",
    "rs = ShuffleSplit(n_splits=500, test_size=.25, random_state=0)\n",
    "cv = rs.split(dataset_features_arr)\n",
    "\n",
    "correlation_ridge = []\n",
    "mae_ridge = []\n",
    "X = dataset_features_arr\n",
    "y = dataset_labels_arr.reshape(-1)\n",
    "\n",
    "# for all different split\n",
    "for train, test in cv:\n",
    "    rl = Ridge(**lr_random.best_params_)\n",
    "    rl.fit(X[train], y[train])\n",
    "    predictions = rl.predict(X[test]).reshape(-1)\n",
    "    pearson = pearsonr(y[test], predictions)[0]\n",
    "    error = abs(predictions - y[test])\n",
    "    correlation_ridge.append(pearson)\n",
    "    mae_ridge.append(error)\n",
    "\n",
    "# Print the score of interest\n",
    "print(np.array(correlation_ridge).mean())\n",
    "print(np.array(mae_ridge).mean())\n",
    "print(np.array(correlation_ridge).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and save the distribution\n",
    "sns.distplot(correlation_ridge)\n",
    "plt.xlabel('Pearson Correlation')\n",
    "plt.ylabel('Counts')\n",
    "plt.savefig('data/imgs/ridge.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 3 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing a randomized grid search and cross validatino to find the best SVM model \n",
    "\n",
    "kernel = ('linear', 'poly', 'rbf')\n",
    "C = [int(x) for x in np.linspace(1, 150, 10)]\n",
    "\n",
    "random_grid = {'kernel': kernel,\n",
    "               'C': C}\n",
    "svm = SVR()\n",
    "svm_random = RandomizedSearchCV(estimator = svm, param_distributions = random_grid, \n",
    "                                n_iter = 10, cv = 2, scoring='neg_mean_squared_error')\n",
    "svm_random.fit(dataset_features_arr, dataset_labels_arr.ravel())\n",
    "print(svm_random.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the next cell, a cross validation over many randomly created splits are run on each of the best model to provide estimates of the score distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = ShuffleSplit(n_splits=10, test_size=.25, random_state=0)\n",
    "cv = rs.split(dataset_features_arr)\n",
    "\n",
    "correlation_svm = []\n",
    "mae_svm = []\n",
    "X = dataset_features_arr\n",
    "y = dataset_labels_arr.reshape(-1)\n",
    "\n",
    "for train, test in cv\n",
    "    svm = SVR(**svm_random.best_params_)\n",
    "    svm.fit(X[train], y[train])\n",
    "    predictions = svm.predict(X[test]).reshape(-1)\n",
    "    pearson = pearsonr(y[test], predictions)[0]\n",
    "    error = abs(predictions - y[test])\n",
    "    correlation_svm.append(pearson)\n",
    "    mae_svm.append(error)\n",
    "    \n",
    "print(np.array(correlation_svm).mean())\n",
    "print(np.array(mae_svm).mean())\n",
    "print(np.array(correlation_svm).std())\n",
    "\n",
    "sns.distplot(correlation_svm)\n",
    "plt.xlabel('Pearson Correlation')\n",
    "plt.ylabel('Counts')\n",
    "plt.savefig('data/imgs/svr.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing a randomized grid search and cross validation to find the best random forest model \n",
    "# Setting the different parameters\n",
    "\n",
    "n_estimators = [500, 1000]\n",
    "max_depth = [1,2]\n",
    "bootstrap = [True]# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'bootstrap':bootstrap}\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, \n",
    "                               n_iter = 2, cv = 2, random_state=42, scoring='neg_mean_squared_error')\n",
    "rf_random.fit(dataset_features_arr, dataset_labels_arr.ravel())\n",
    "print(rf_random.best_params_)\n",
    "print(rf_random.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highlighting the most important features of the model\n",
    "rf = RandomForestRegressor(**{'n_estimators': 1000, 'max_depth': 2, 'bootstrap': True})\n",
    "rf.fit(dataset_features_arr, dataset_labels_arr.ravel())\n",
    "\n",
    "importances = list(rf.feature_importances_)\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(dataset_features_list, importances)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the next cell, a cross validation over many randomly created splits are run on each of the best model to provide estimates of the score distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = ShuffleSplit(n_splits=10, test_size=.25, random_state=0)\n",
    "cv = rs.split(dataset_features_arr)\n",
    "\n",
    "correlation_rf = []\n",
    "mae_rf = []\n",
    "X = dataset_features_arr\n",
    "y = dataset_labels_arr.reshape(-1)\n",
    "\n",
    "for train, test in cv\n",
    "    rf = RandomForestRegressor(**rf_random.best_params_)\n",
    "    rf.fit(X[train], y[train])\n",
    "    predictions = rf.predict(X[test]).reshape(-1)\n",
    "    pearson = pearsonr(y[test], predictions)[0]\n",
    "    error = abs(predictions - y[test])\n",
    "    correlation_rf.append(pearson)\n",
    "    mae_rf.append(error)\n",
    "    \n",
    "print(np.array(correlation_rf).mean())\n",
    "print(np.array(mae_rf).mean())\n",
    "print(np.array(correlation_rf).std())\n",
    "\n",
    "sns.distplot(correlation_rf)\n",
    "plt.xlabel('Pearson Correlation')\n",
    "plt.ylabel('Counts')\n",
    "plt.savefig('data/imgs/rf.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Nerual Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model tested were neural networks. The following provides the implementation of the network using Pytorch, as well as a cross validation on the tested architecture. In this section, the full LASER embedding 1024 dimension vectors were included in the feartures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the laser embeddings daatsets\n",
    "english_laser = np.load('data/laser_embeddings/laser_1024_english.npy')\n",
    "german_laser = np.load('data/laser_embeddings/laser_1024_german.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the train and validation features\n",
    "english_laser_train = english_laser[:8000,:]\n",
    "german_laser_train = german_laser[:8000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get arrays from pandas columns\n",
    "english_laser_train = np.array(english_laser_train)\n",
    "german_laser_train = np.array(german_laser_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the total features\n",
    "laser_features = np.concatenate((english_laser_train, german_laser_train), axis=1)\n",
    "train_val_features = np.concatenate((laser_features, dataset_features_arr), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (encoder1): Linear(in_features=2048, out_features=10, bias=True)\n",
      "  (dropout_encoder1): Dropout(p=0.5, inplace=False)\n",
      "  (encoder2): Linear(in_features=10, out_features=15, bias=True)\n",
      "  (dropout_encoder2): Dropout(p=0.5, inplace=False)\n",
      "  (bn_encoder): BatchNorm1d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=31, out_features=6, bias=True)\n",
      "  (dropout_fc1): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=6, out_features=1, bias=True)\n",
      "  (dropout_fc2): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Constructing the model\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, x):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        x_laser = x[:, :2048]\n",
    "        x_baseline = x[:, 2048:]\n",
    "        \n",
    "        encoding_size = 15\n",
    "        self.encoder1 = nn.Linear(x_laser.shape[1], 10)\n",
    "        nn.init.xavier_uniform_(self.encoder1.weight, gain=1.0)\n",
    "        self.dropout_encoder1 = nn.Dropout(p=0.5)\n",
    "        \n",
    "        self.encoder2 = nn.Linear(10, encoding_size)\n",
    "        nn.init.xavier_uniform_(self.encoder1.weight, gain=1.0)\n",
    "        self.dropout_encoder2 = nn.Dropout(p=0.5)\n",
    "        self.bn_encoder = nn.BatchNorm1d(num_features=encoding_size)\n",
    "        \n",
    "        x = torch.zeros(x_laser.shape[0], encoding_size + x_baseline.shape[1])\n",
    "        \n",
    "        self.fc1 = nn.Linear(x.shape[1], 6) \n",
    "        nn.init.xavier_uniform_(self.fc1.weight, gain=1.0)\n",
    "        self.dropout_fc1 = nn.Dropout(p=0.5)\n",
    "        \n",
    "        self.fc2 = nn.Linear(6, 1)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight, gain=1.0)\n",
    "        self.dropout_fc2 = nn.Dropout(p=0.5)\n",
    "        \n",
    "#         self.fc3 = nn.Linear(3, 1)\n",
    "#         nn.init.xavier_uniform_(self.fc2.weight, gain=1.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x_laser = x[:, :2048]\n",
    "        x_baseline = x[:, 2048:]\n",
    "        \n",
    "        x_laser = x_laser.view(-1, self.num_flat_features(x_laser))\n",
    "        x_baseline = x_baseline.view(-1, self.num_flat_features(x_baseline))\n",
    "        \n",
    "        x_laser = self.encoder1(x_laser)\n",
    "        x_laser = self.dropout_encoder1(x_laser)\n",
    "        x_laser = F.relu(x_laser)\n",
    "        \n",
    "        x_laser = self.encoder2(x_laser)\n",
    "#         x_laser = self.dropout_encoder2(x_laser)\n",
    "        x_laser = F.relu(x_laser)\n",
    "        x_laser = self.bn_encoder(x_laser)\n",
    "        \n",
    "        \n",
    "        x = torch.cat((x_laser, x_baseline), dim=1)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "#         x = self.dropout_fc1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "#         x = self.dropout_fc2(x)\n",
    "#         x = F.relu(x)\n",
    "        \n",
    "#         x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net(train_val_features)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 -0.02944079262970075 -0.025213594014865774\n",
      "Epoch  1 -0.01175644548889364 -0.03250766463941739\n",
      "Epoch  2 -0.006735831321859406 -0.016802109737217727\n",
      "Epoch  3 0.003431444878047189 -0.03207921840964783\n",
      "Epoch  4 0.02903109773281274 0.011315651638896293\n",
      "Epoch  5 0.029358323820659355 -0.010061562697622137\n",
      "Epoch  6 0.038649121502183754 -0.0035826851149515643\n",
      "Epoch  7 0.04815560239985098 0.019335264359989904\n",
      "Epoch  8 0.0634790487078665 0.017149663101207052\n",
      "Epoch  9 0.08135475774907965 0.026436420166071842\n",
      "Epoch  10 0.08667350717247588 0.041879370720633136\n",
      "Epoch  11 0.09691185100045482 0.016732541252108935\n",
      "Epoch  12 0.09752580486872553 0.027291230143670506\n",
      "Epoch  13 0.09204197968928536 0.049863918965120824\n",
      "Epoch  14 0.11034144044088914 0.07703609161333533\n",
      "Epoch  15 0.12526958019262224 0.052577350257110154\n",
      "Epoch  16 0.12015184313609692 0.03829942497726205\n",
      "Epoch  17 0.14281559986787365 0.06829813972356705\n",
      "Epoch  18 0.16183759180127516 0.027158155523315172\n",
      "Epoch  19 0.14695642149270888 0.04483623079805158\n",
      "Epoch  20 0.16279497790033684 0.05800372244772667\n",
      "Epoch  21 0.1730261799810516 0.058265697926764594\n",
      "Epoch  22 0.18478942133567916 0.06362163030580326\n",
      "Epoch  23 0.1893457318244449 0.07238494433563467\n",
      "Epoch  24 0.19442302243593648 0.05853201289346855\n",
      "Epoch  25 0.20256491484713862 0.050937583275230874\n",
      "Epoch  26 0.1958710593603786 0.043082824840714955\n",
      "Epoch  27 0.2215958240804563 0.06900315399113952\n",
      "Epoch  28 0.2058905293820562 0.06894745863325066\n",
      "Epoch  29 0.24572810174879112 0.059178178902858605\n",
      "Epoch  30 0.2331401455918476 0.08943279770180139\n",
      "Epoch  31 0.23300946049576848 0.04767160926314215\n",
      "Epoch  32 0.2536259183133844 0.05813888866312125\n",
      "Epoch  33 0.2630443533630765 0.0751638887802848\n",
      "Epoch  34 0.2621750251236059 0.06084910133765859\n",
      "Epoch  35 0.2584939393142058 0.04595587125599081\n",
      "Epoch  36 0.26802028578293974 0.055381585846917256\n",
      "Epoch  37 0.27652790931650784 0.07690985652131413\n",
      "Epoch  38 0.28027860169869356 0.06851732732373123\n",
      "Epoch  39 0.2758647574803413 0.07294511331644479\n",
      "Epoch  40 0.30160860709561976 0.08168710308491524\n",
      "Epoch  41 0.31075976239325775 0.07228449452710188\n",
      "Epoch  42 0.3019747467430114 0.06364322119329344\n",
      "Epoch  43 0.316319647992724 0.06309411582550167\n",
      "Epoch  44 0.3177013042789859 0.06500574412502767\n",
      "Epoch  45 0.3072017828155328 0.0561042694080901\n",
      "Epoch  46 0.32193877763142287 0.08077749310406504\n",
      "Epoch  47 0.3177775475411574 0.05017756670934737\n",
      "Epoch  48 0.33034795757699614 0.06704849079541937\n",
      "Epoch  49 0.34755188956208 0.05750858579328232\n",
      "Epoch  50 0.33678288216617336 0.05807018455290759\n",
      "Epoch  51 0.3346209450596107 0.04440232847188544\n",
      "Epoch  52 0.34186751453174735 0.06392115862608252\n",
      "Epoch  53 0.34403946733768037 0.052700342352614726\n",
      "Epoch  54 0.3640587119121058 0.08786370016288422\n",
      "Epoch  55 0.3624826936493867 0.06365182884249419\n",
      "Epoch  56 0.35678438631311904 0.057564016431058254\n",
      "Epoch  57 0.35224476150737327 0.042611406230801945\n",
      "Epoch  58 0.3652885317031909 0.060102732083195505\n",
      "Epoch  59 0.376325622927401 0.06282898929114014\n",
      "Epoch  60 0.37057691179253494 0.0588060319531157\n",
      "Epoch  61 0.36639349835838203 0.08303246214934873\n",
      "Epoch  62 0.3888244453394824 0.04866000040202717\n",
      "Epoch  63 0.3725960594752565 0.06809536057399389\n",
      "Epoch  64 0.40174027368701026 0.05912451466447581\n",
      "Epoch  65 0.3781819004864947 0.07605705811803827\n",
      "Epoch  66 0.39986412405378335 0.04657417857909271\n",
      "Epoch  67 0.413212436894494 0.018334391474180596\n",
      "Epoch  68 0.40764479857977853 0.031059357369430926\n",
      "Epoch  69 0.4026353594311357 0.06634287274734064\n",
      "Epoch  70 0.39867019063142106 0.07711925071114992\n",
      "Epoch  71 0.4334662784748301 0.0457371148587411\n",
      "Epoch  72 0.41693745060875786 0.03812047464620048\n",
      "Epoch  73 0.40757010998540355 0.04790768760492155\n",
      "Epoch  74 0.4293628400175634 0.06290337186587128\n",
      "Epoch  75 0.41978614364116706 0.06583090924741884\n",
      "Epoch  76 0.4372566115291583 0.044183668274083515\n",
      "Epoch  77 0.4365329122762608 0.05937190874595838\n",
      "Epoch  78 0.42680935014334787 0.052748565122124946\n",
      "Epoch  79 0.43925061057248477 0.023539453555382915\n",
      "Epoch  80 0.41657796086997045 0.08591907301745441\n",
      "Epoch  81 0.4485769948832653 0.06365184073047732\n",
      "Epoch  82 0.44343659227454113 0.03274150630646499\n",
      "Epoch  83 0.4382144891890454 0.03731673213288354\n",
      "Epoch  84 0.4561527606960223 0.04945415691672686\n",
      "Epoch  85 0.45658903763115644 0.046864188484456226\n",
      "Epoch  86 0.4530814011746227 0.04976807372980417\n",
      "Epoch  87 0.4654775226308362 0.06234524349545421\n",
      "Epoch  88 0.46310009454996415 0.05626911422865633\n",
      "Epoch  89 0.4593614973462735 0.08114216928115905\n",
      "Epoch  90 0.45894319800814154 0.040644299508936\n",
      "Epoch  91 0.4754859697625131 0.050198501462415016\n",
      "Epoch  92 0.45917002028605935 0.045797735948099445\n",
      "Epoch  93 0.46578399762557354 0.03314750064884066\n",
      "Epoch  94 0.4735285588615141 0.026238050287821547\n",
      "Epoch  95 0.47819490948902094 0.060545927996952714\n",
      "Epoch  96 0.4790101749139418 0.044860958372503604\n",
      "Epoch  97 0.4791280592260935 0.054939262814174744\n",
      "Epoch  98 0.48353270163542755 0.0384050808236632\n",
      "Epoch  99 0.4986738824122235 0.0392893370138723\n",
      "Epoch  100 0.4785038763230748 0.029648209444048487\n",
      "Epoch  101 0.49684279511566215 0.019953962893029368\n",
      "Epoch  102 0.48996634773946135 0.03185069458032068\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-403a256a455c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;31m# print statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Performing cross validation over random splits of the data, and printing the best pearson correlation \n",
    "# coefficents obtained during on the test data\n",
    "\n",
    "rs = ShuffleSplit(n_splits=2, test_size=.25, random_state=0)\n",
    "cv = rs.split(dataset_features_arr)\n",
    "\n",
    "for train_idx, val_idx in cv:\n",
    "    \n",
    "    # Rededining the model to restars learning\n",
    "    net = Net(train_val_features)\n",
    "    \n",
    "    train_features = train_val_features[train_idx]\n",
    "    train_labels = dataset_labels_arr[train_idx].reshape(-1)\n",
    "    \n",
    "    val_features = train_val_features[val_idx]\n",
    "    val_labels = dataset_labels_arr[val_idx].reshape(-1)\n",
    "    \n",
    "    # Making to tensors as required by Pytorch to propagate the gradients\n",
    "    train_features_ten, train_labels_ten = Tensor(train_features), Tensor(train_labels.reshape(-1,1))\n",
    "\n",
    "    # Standardizing the inputs\n",
    "    means = train_features_ten.mean(dim=0, keepdim=True)\n",
    "    stds = train_features_ten.std(dim=0, keepdim=True)\n",
    "    normalized_train = (train_features_ten - means) / stds\n",
    "\n",
    "    val_features_ten = (Tensor(val_features)- means) / stds\n",
    "    test_labels = Tensor((val_labels).reshape(-1, 1))\n",
    "\n",
    "    # Creating the dataloaders to create the batches and iterate over epochs\n",
    "    train_data = TensorDataset(normalized_train, train_labels_ten)\n",
    "    train_loader = DataLoader(train_data, shuffle=True, batch_size=32)\n",
    "\n",
    "#     criterion = nn.MSELoss()\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=1e-4, betas=(0.5, 0.999))\n",
    "\n",
    "    test_pearson=[]\n",
    "    train_pearson=[]\n",
    "\n",
    "    \n",
    "    for epoch in range(300):\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "            inputs, labels = data\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # No grads to prevent from propagating the gradient from the test data\n",
    "        with torch.no_grad():\n",
    "            # Getting the test correlation\n",
    "            predictions = net(val_features_ten)\n",
    "            test_loss = criterion(predictions, test_labels).item()\n",
    "            pearson_test = pearsonr(val_labels, predictions.numpy().reshape(-1,))[0]\n",
    "            test_pearson.append(pearson_test)\n",
    "\n",
    "            #train correlation\n",
    "            predictions = net(normalized_train)\n",
    "            pearson_train = pearsonr(train_labels, predictions.numpy().reshape(-1,))[0]\n",
    "            train_pearson.append(pearson_train)\n",
    "            \n",
    "            print('Epoch ', epoch, pearson_train, pearson_test)\n",
    "\n",
    "    print('Test: ', test_pearson.index(max(test_pearson)), max(test_pearson))\n",
    "    print('Train: ', train_pearson.index(max(train_pearson)), max(train_pearson))\n",
    "    plt.plot(test_pearson)\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section provides provides the code which trains our best models (ie. the Ridge linear regression and PLS regrssion using the best found hyper parameters) on the full train and validation dataset to predict the test scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with the best Ridge regression \n",
    "lr_test = Ridge(**{'normalize': True, 'max_iter': 595, 'alpha': 0.2222222222222222})\n",
    "lr_test.fit(dataset_features_arr, dataset_labels_arr)\n",
    "predictions = lr_test.predict(test_features_arr).reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions with the best PLS regression \n",
    "pls_test = PLSRegression(**{'scale': True, 'n_components': 2, 'max_iter': 339})\n",
    "pls_test.fit(dataset_features_arr, dataset_labels_arr)\n",
    "predictions = pls_test.predict(test_features_arr).reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictions directory if don't exist\n",
    "predictions_dir = os.path.join(os.getcwd(), 'data', 'predictions')\n",
    "if not os.path.exists(predictions_dir):\n",
    "    os.mkdir(predictions_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the scores to be tested on Codalab\n",
    "\n",
    "def writeScores(method_name,scores):\n",
    "    fn = \"data/predictions/predictions.txt\"\n",
    "    print(\"\")\n",
    "    with open(fn, 'w') as output_file:\n",
    "        for idx,x in enumerate(scores):\n",
    "            #out =  metrics[idx]+\":\"+str(\"{0:.2f}\".format(x))+\"\\n\"\n",
    "            #print(out)\n",
    "            output_file.write(f\"{x}\\n\")\n",
    "\n",
    "writeScores(\"model_name\",predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
